## DEFEND THE CENTER RAINBOW

Run: 99_20251209_020022

uv run levd.py --algorithm rainbow --scenario defend_the_center --train_levels 0 --train_maps 1 --test_levels 0 --test_maps 1 --seed 99 --epoch 80 --step-per-collect 10 --device cuda --batch-size 64

Epoch #1: 100001it [05:47, 287.62it/s, env_step=100000, len=120, loss=2.937, n/ep=1, n/st=10, rew=2.66]                                                                                                                                                   
Epoch #1: test_reward: 4.928800 ± 1.009814, best_reward: 4.928800 ± 1.009814 in #1
Epoch #2: 100001it [05:50, 284.91it/s, env_step=200000, len=98, loss=2.937, n/ep=0, n/st=10, rew=1.70]                                                                                                                                                    
Epoch #2: test_reward: 4.976900 ± 1.140625, best_reward: 4.976900 ± 1.140625 in #2
Epoch #3: 100001it [05:50, 285.72it/s, env_step=300000, len=65, loss=2.843, n/ep=0, n/st=10, rew=-0.18]                                                                                                                                                   
Epoch #3: test_reward: 4.999700 ± 1.451469, best_reward: 4.999700 ± 1.451469 in #3
Epoch #4: 100001it [05:50, 285.40it/s, env_step=400000, len=70, loss=2.720, n/ep=0, n/st=10, rew=0.83]                                                                                                                                                    
Epoch #4: test_reward: 6.543500 ± 1.730099, best_reward: 6.543500 ± 1.730099 in #4
Epoch #5: 100001it [05:43, 291.51it/s, env_step=500000, len=58, loss=2.640, n/ep=0, n/st=10, rew=-0.17]                                                                                                                                                   
Epoch #5: test_reward: 4.177900 ± 1.104477, best_reward: 6.543500 ± 1.730099 in #4
Epoch #6: 100001it [05:42, 292.05it/s, env_step=600000, len=94, loss=2.645, n/ep=0, n/st=10, rew=3.74]                                                                                                                                                    
Epoch #6: test_reward: 4.884700 ± 0.947450, best_reward: 6.543500 ± 1.730099 in #4
Epoch #7: 100001it [05:42, 291.57it/s, env_step=700000, len=98, loss=2.578, n/ep=0, n/st=10, rew=2.75]                                                                                                                                                    
Epoch #7: test_reward: 5.335800 ± 1.052584, best_reward: 6.543500 ± 1.730099 in #4
Epoch #8: 100001it [05:42, 291.76it/s, env_step=800000, len=161, loss=2.493, n/ep=1, n/st=10, rew=6.65]                                                                                                                                                   
Epoch #8: test_reward: 5.656400 ± 0.882819, best_reward: 6.543500 ± 1.730099 in #4
Epoch #9: 100001it [05:41, 292.51it/s, env_step=900000, len=128, loss=2.462, n/ep=0, n/st=10, rew=5.67]                                                                                                                                                   
Epoch #9: test_reward: 4.746100 ± 1.074830, best_reward: 6.543500 ± 1.730099 in #4
Epoch #10: 100001it [05:42, 291.69it/s, env_step=1000000, len=131, loss=2.277, n/ep=0, n/st=10, rew=6.68]                                                                                                                                                 
Epoch #10: test_reward: 4.817500 ± 1.139081, best_reward: 6.543500 ± 1.730099 in #4
Epoch #11: 100001it [05:42, 292.13it/s, env_step=1100000, len=98, loss=2.404, n/ep=0, n/st=10, rew=4.72]                                                                                                                                                  
Epoch #11: test_reward: 4.990900 ± 1.030123, best_reward: 6.543500 ± 1.730099 in #4
Epoch #12: 100001it [05:41, 292.49it/s, env_step=1200000, len=131, loss=2.220, n/ep=0, n/st=10, rew=4.69]                                                                                                                                                 
Epoch #12: test_reward: 5.248200 ± 1.049841, best_reward: 6.543500 ± 1.730099 in #4
Epoch #13: 100001it [05:41, 292.66it/s, env_step=1300000, len=152, loss=2.188, n/ep=0, n/st=10, rew=5.67]                                                                                                                                                 
Epoch #13: test_reward: 4.893400 ± 1.002310, best_reward: 6.543500 ± 1.730099 in #4
Epoch #14: 100001it [05:41, 293.15it/s, env_step=1400000, len=133, loss=2.151, n/ep=0, n/st=10, rew=6.70]                                                                                                                                                 
Epoch #14: test_reward: 6.103900 ± 0.908505, best_reward: 6.543500 ± 1.730099 in #4
Epoch #15: 100001it [05:41, 293.02it/s, env_step=1500000, len=130, loss=2.127, n/ep=0, n/st=10, rew=4.70]                                                                                                                                                 
Epoch #15: test_reward: 6.831500 ± 1.461081, best_reward: 6.831500 ± 1.461081 in #15
Epoch #16: 100001it [05:41, 293.07it/s, env_step=1600000, len=132, loss=2.018, n/ep=0, n/st=10, rew=5.67]                                                                                                                                                 
Epoch #16: test_reward: 5.275700 ± 1.246377, best_reward: 6.831500 ± 1.461081 in #15
Epoch #17: 100001it [05:40, 293.39it/s, env_step=1700000, len=105, loss=2.014, n/ep=0, n/st=10, rew=4.68]                                                                                                                                                 
Epoch #17: test_reward: 6.801400 ± 1.271575, best_reward: 6.831500 ± 1.461081 in #15
Epoch #18: 100001it [05:41, 292.92it/s, env_step=1800000, len=145, loss=1.991, n/ep=1, n/st=10, rew=5.67]                                                                                                                                                 
Epoch #18: test_reward: 5.963300 ± 1.161028, best_reward: 6.831500 ± 1.461081 in #15
Epoch #19: 100001it [05:41, 292.47it/s, env_step=1900000, len=199, loss=1.954, n/ep=0, n/st=10, rew=7.69]                                                                                                                                                 
Epoch #19: test_reward: 5.746900 ± 1.415794, best_reward: 6.831500 ± 1.461081 in #15
Epoch #20: 100001it [05:40, 293.38it/s, env_step=2000000, len=116, loss=1.913, n/ep=0, n/st=10, rew=4.70]                                                                                                                                                 
Epoch #20: test_reward: 5.476500 ± 1.115606, best_reward: 6.831500 ± 1.461081 in #15
Epoch #21: 100001it [05:41, 292.85it/s, env_step=2100000, len=127, loss=1.836, n/ep=1, n/st=10, rew=5.68]                                                                                                                                                 
Epoch #21: test_reward: 6.251200 ± 1.079118, best_reward: 6.831500 ± 1.461081 in #15
Epoch #22: 100001it [05:41, 293.18it/s, env_step=2200000, len=165, loss=1.892, n/ep=0, n/st=10, rew=6.69]                                                                                                                                                 
Epoch #22: test_reward: 4.339900 ± 1.422328, best_reward: 6.831500 ± 1.461081 in #15
Epoch #23: 100001it [05:40, 293.72it/s, env_step=2300000, len=144, loss=1.979, n/ep=0, n/st=10, rew=6.66]                                                                                                                                                 
Epoch #23: test_reward: 6.488800 ± 1.249635, best_reward: 6.831500 ± 1.461081 in #15
Epoch #24: 100001it [05:40, 293.31it/s, env_step=2400000, len=157, loss=1.958, n/ep=0, n/st=10, rew=7.68]                                                                                                                                                 
Epoch #24: test_reward: 6.153300 ± 2.240690, best_reward: 6.831500 ± 1.461081 in #15
Epoch #25: 100001it [05:41, 293.09it/s, env_step=2500000, len=136, loss=1.885, n/ep=0, n/st=10, rew=5.64]                                                                                                                                                 
Epoch #25: test_reward: 4.820000 ± 1.728815, best_reward: 6.831500 ± 1.461081 in #15
Epoch #26: 100001it [05:41, 293.02it/s, env_step=2600000, len=150, loss=1.886, n/ep=0, n/st=10, rew=5.67]                                                                                                                                                 
Epoch #26: test_reward: 5.031300 ± 1.443167, best_reward: 6.831500 ± 1.461081 in #15
Epoch #27: 100001it [05:41, 292.58it/s, env_step=2700000, len=112, loss=1.912, n/ep=0, n/st=10, rew=4.68]                                                                                                                                                 
Epoch #27: test_reward: 4.753300 ± 0.889206, best_reward: 6.831500 ± 1.461081 in #15
Epoch #28: 100001it [05:40, 293.41it/s, env_step=2800000, len=110, loss=1.909, n/ep=0, n/st=10, rew=4.67]                                                                                                                                                 
Epoch #28: test_reward: 6.170900 ± 1.490481, best_reward: 6.831500 ± 1.461081 in #15
Epoch #29: 100001it [05:40, 293.80it/s, env_step=2900000, len=135, loss=1.859, n/ep=0, n/st=10, rew=7.65]                                                                                                                                                 
Epoch #29: test_reward: 5.299300 ± 1.258436, best_reward: 6.831500 ± 1.461081 in #15
Epoch #30: 100001it [05:41, 293.03it/s, env_step=3000000, len=137, loss=1.832, n/ep=0, n/st=10, rew=5.71]                                                                                                                                                 
Epoch #30: test_reward: 6.167600 ± 1.526843, best_reward: 6.831500 ± 1.461081 in #15
Epoch #31: 100001it [05:41, 292.85it/s, env_step=3100000, len=66, loss=1.840, n/ep=0, n/st=10, rew=1.81]                                                                                                                                                  
Epoch #31: test_reward: 4.945700 ± 1.878615, best_reward: 6.831500 ± 1.461081 in #15
Epoch #32: 100001it [05:41, 293.16it/s, env_step=3200000, len=111, loss=1.773, n/ep=0, n/st=10, rew=3.71]                                                                                                                                                 
Epoch #32: test_reward: 5.908000 ± 1.381954, best_reward: 6.831500 ± 1.461081 in #15
Epoch #33: 100001it [05:40, 293.42it/s, env_step=3300000, len=120, loss=1.757, n/ep=1, n/st=10, rew=5.72]                                                                                                                                                 
Epoch #33: test_reward: 5.911100 ± 2.588306, best_reward: 6.831500 ± 1.461081 in #15
Epoch #34: 100001it [05:41, 292.83it/s, env_step=3400000, len=118, loss=1.758, n/ep=0, n/st=10, rew=5.72]                                                                                                                                                 
Epoch #34: test_reward: 5.238700 ± 2.252482, best_reward: 6.831500 ± 1.461081 in #15
Epoch #35: 100001it [05:40, 293.31it/s, env_step=3500000, len=178, loss=1.716, n/ep=0, n/st=10, rew=7.67]                                                                                                                                                 
Epoch #35: test_reward: 5.114300 ± 2.042774, best_reward: 6.831500 ± 1.461081 in #15
Epoch #36: 100001it [05:40, 293.70it/s, env_step=3600000, len=122, loss=1.748, n/ep=0, n/st=10, rew=4.68]                                                                                                                                                 
Epoch #36: test_reward: 4.594700 ± 1.955914, best_reward: 6.831500 ± 1.461081 in #15
Epoch #37: 100001it [05:40, 293.34it/s, env_step=3700000, len=152, loss=1.782, n/ep=0, n/st=10, rew=6.72]                                                                                                                                                 
Epoch #37: test_reward: 6.723900 ± 2.787638, best_reward: 6.831500 ± 1.461081 in #15
Epoch #38: 100001it [05:40, 293.61it/s, env_step=3800000, len=124, loss=1.780, n/ep=0, n/st=10, rew=5.75]                                                                                                                                                 
Epoch #38: test_reward: 6.779800 ± 2.594781, best_reward: 6.831500 ± 1.461081 in #15
Epoch #39: 100001it [05:40, 293.48it/s, env_step=3900000, len=186, loss=1.836, n/ep=0, n/st=10, rew=8.70]                                                                                                                                                 
Epoch #39: test_reward: 6.406200 ± 2.540954, best_reward: 6.831500 ± 1.461081 in #15
Epoch #40: 100001it [05:40, 294.09it/s, env_step=4000000, len=109, loss=1.809, n/ep=0, n/st=10, rew=3.73]                                                                                                                                                 
Epoch #40: test_reward: 6.259400 ± 2.429192, best_reward: 6.831500 ± 1.461081 in #15
Epoch #41: 100001it [05:40, 293.71it/s, env_step=4100000, len=116, loss=1.787, n/ep=0, n/st=10, rew=3.67]                                                                                                                                                 
Epoch #41: test_reward: 5.527800 ± 2.371915, best_reward: 6.831500 ± 1.461081 in #15
Epoch #42: 100001it [05:40, 293.95it/s, env_step=4200000, len=151, loss=1.782, n/ep=0, n/st=10, rew=7.70]                                                                                                                                                 
Epoch #42: test_reward: 9.421100 ± 2.851179, best_reward: 9.421100 ± 2.851179 in #42
Epoch #43: 100001it [05:40, 293.48it/s, env_step=4300000, len=89, loss=1.837, n/ep=0, n/st=10, rew=2.80]                                                                                                                                                  
Epoch #43: test_reward: 6.306600 ± 1.548140, best_reward: 9.421100 ± 2.851179 in #42
Epoch #44: 100001it [05:40, 293.84it/s, env_step=4400000, len=125, loss=1.816, n/ep=0, n/st=10, rew=4.67]                                                                                                                                                 
Epoch #44: test_reward: 8.161500 ± 2.421237, best_reward: 9.421100 ± 2.851179 in #42
Epoch #45: 100001it [05:40, 293.65it/s, env_step=4500000, len=91, loss=1.745, n/ep=0, n/st=10, rew=4.72]                                                                                                                                                  
Epoch #45: test_reward: 6.741100 ± 1.965002, best_reward: 9.421100 ± 2.851179 in #42
Epoch #46: 100001it [05:40, 293.42it/s, env_step=4600000, len=123, loss=1.750, n/ep=0, n/st=10, rew=4.69]                                                                                                                                                 
Epoch #46: test_reward: 7.817200 ± 2.101133, best_reward: 9.421100 ± 2.851179 in #42
Epoch #47: 100001it [05:40, 293.71it/s, env_step=4700000, len=184, loss=1.641, n/ep=0, n/st=10, rew=8.68]                                                                                                                                                 
Epoch #47: test_reward: 6.993000 ± 1.682544, best_reward: 9.421100 ± 2.851179 in #42
Epoch #48: 100001it [05:40, 293.27it/s, env_step=4800000, len=107, loss=1.696, n/ep=0, n/st=10, rew=5.67]                                                                                                                                                 
Epoch #48: test_reward: 5.350700 ± 1.307830, best_reward: 9.421100 ± 2.851179 in #42
Epoch #49: 100001it [05:40, 293.54it/s, env_step=4900000, len=157, loss=1.626, n/ep=0, n/st=10, rew=6.67]                                                                                                                                                 
Epoch #49: test_reward: 6.503500 ± 1.409019, best_reward: 9.421100 ± 2.851179 in #42
Epoch #50: 100001it [05:40, 293.74it/s, env_step=5000000, len=156, loss=1.693, n/ep=0, n/st=10, rew=6.67]                                                                                                                                                 
Epoch #50: test_reward: 5.094400 ± 1.418138, best_reward: 9.421100 ± 2.851179 in #42
Epoch #51: 100001it [05:40, 293.44it/s, env_step=5100000, len=131, loss=1.636, n/ep=0, n/st=10, rew=4.66]                                                                                                                                                 
Epoch #51: test_reward: 5.638100 ± 1.615750, best_reward: 9.421100 ± 2.851179 in #42
Epoch #52: 100001it [05:41, 292.76it/s, env_step=5200000, len=131, loss=1.571, n/ep=0, n/st=10, rew=4.66]                                                                                                                                                 
Epoch #52: test_reward: 5.459600 ± 1.514042, best_reward: 9.421100 ± 2.851179 in #42
Epoch #53: 100001it [05:40, 293.58it/s, env_step=5300000, len=177, loss=1.611, n/ep=0, n/st=10, rew=5.66]                                                                                                                                                 
Epoch #53: test_reward: 5.901400 ± 1.392418, best_reward: 9.421100 ± 2.851179 in #42
Epoch #54: 100001it [05:40, 293.81it/s, env_step=5400000, len=110, loss=1.589, n/ep=0, n/st=10, rew=1.68]                                                                                                                                                 
Epoch #54: test_reward: 5.412300 ± 1.426920, best_reward: 9.421100 ± 2.851179 in #42
Epoch #55: 100001it [05:41, 293.19it/s, env_step=5500000, len=133, loss=1.465, n/ep=0, n/st=10, rew=6.71]                                                                                                                                                 
Epoch #55: test_reward: 5.166800 ± 1.301250, best_reward: 9.421100 ± 2.851179 in #42
Epoch #56: 100001it [05:41, 293.24it/s, env_step=5600000, len=98, loss=1.549, n/ep=0, n/st=10, rew=3.74]                                                                                                                                                  
Epoch #56: test_reward: 5.740100 ± 1.334616, best_reward: 9.421100 ± 2.851179 in #42
Epoch #57: 100001it [05:40, 293.42it/s, env_step=5700000, len=124, loss=1.567, n/ep=0, n/st=10, rew=6.71]                                                                                                                                                 
Epoch #57: test_reward: 5.718600 ± 1.766930, best_reward: 9.421100 ± 2.851179 in #42
Epoch #58: 100001it [05:41, 292.59it/s, env_step=5800000, len=109, loss=1.535, n/ep=0, n/st=10, rew=2.64]                                                                                                                                                 
Epoch #58: test_reward: 5.031200 ± 1.262499, best_reward: 9.421100 ± 2.851179 in #42
Epoch #59: 100001it [05:40, 293.31it/s, env_step=5900000, len=175, loss=1.574, n/ep=0, n/st=10, rew=7.71]                                                                                                                                                 
Epoch #59: test_reward: 5.014300 ± 1.054285, best_reward: 9.421100 ± 2.851179 in #42
Epoch #60: 100001it [05:40, 293.41it/s, env_step=6000000, len=142, loss=1.505, n/ep=0, n/st=10, rew=5.71]                                                                                                                                                 
Epoch #60: test_reward: 6.309200 ± 1.511434, best_reward: 9.421100 ± 2.851179 in #42
Epoch #61: 100001it [05:40, 293.86it/s, env_step=6100000, len=135, loss=1.516, n/ep=0, n/st=10, rew=4.66]                                                                                                                                                 
Epoch #61: test_reward: 4.357400 ± 1.506943, best_reward: 9.421100 ± 2.851179 in #42
Epoch #62: 100001it [05:40, 293.52it/s, env_step=6200000, len=156, loss=1.610, n/ep=0, n/st=10, rew=6.65]                                                                                                                                                 
Epoch #62: test_reward: 5.891600 ± 1.467025, best_reward: 9.421100 ± 2.851179 in #42
Epoch #63: 100001it [05:41, 293.12it/s, env_step=6300000, len=126, loss=1.533, n/ep=1, n/st=10, rew=5.67]                                                                                                                                                 
Epoch #63: test_reward: 6.375500 ± 1.675872, best_reward: 9.421100 ± 2.851179 in #42
Epoch #64: 100001it [05:40, 293.30it/s, env_step=6400000, len=129, loss=1.526, n/ep=0, n/st=10, rew=5.68]                                                                                                                                                 
Epoch #64: test_reward: 6.603600 ± 1.499366, best_reward: 9.421100 ± 2.851179 in #42
Epoch #65: 100001it [05:40, 293.84it/s, env_step=6500000, len=124, loss=1.496, n/ep=0, n/st=10, rew=5.66]                                                                                                                                                 
Epoch #65: test_reward: 6.847400 ± 1.407353, best_reward: 9.421100 ± 2.851179 in #42
Epoch #66: 100001it [05:41, 293.02it/s, env_step=6600000, len=187, loss=1.499, n/ep=0, n/st=10, rew=6.66]                                                                                                                                                 
Epoch #66: test_reward: 6.724100 ± 1.608804, best_reward: 9.421100 ± 2.851179 in #42
Epoch #67: 100001it [05:41, 293.18it/s, env_step=6700000, len=102, loss=1.533, n/ep=1, n/st=10, rew=3.73]                                                                                                                                                 
Epoch #67: test_reward: 6.428400 ± 1.636641, best_reward: 9.421100 ± 2.851179 in #42
Epoch #68: 100001it [05:41, 293.04it/s, env_step=6800000, len=130, loss=1.504, n/ep=0, n/st=10, rew=5.67]                                                                                                                                                 
Epoch #68: test_reward: 6.300000 ± 1.456777, best_reward: 9.421100 ± 2.851179 in #42
Epoch #69: 100001it [05:41, 293.08it/s, env_step=6900000, len=181, loss=1.594, n/ep=0, n/st=10, rew=8.69]                                                                                                                                                 
Epoch #69: test_reward: 5.864800 ± 1.557625, best_reward: 9.421100 ± 2.851179 in #42
Epoch #70: 100001it [05:46, 288.34it/s, env_step=7000000, len=203, loss=1.567, n/ep=0, n/st=10, rew=8.66]                                                                                                                                                 
Epoch #70: test_reward: 6.624000 ± 1.370065, best_reward: 9.421100 ± 2.851179 in #42
Epoch #71: 100001it [05:46, 288.24it/s, env_step=7100000, len=152, loss=1.499, n/ep=0, n/st=10, rew=6.69]                                                                                                                                                 
Epoch #71: test_reward: 6.168800 ± 1.428483, best_reward: 9.421100 ± 2.851179 in #42
Epoch #72: 100001it [05:45, 289.36it/s, env_step=7200000, len=149, loss=1.541, n/ep=0, n/st=10, rew=6.62]                                                                                                                                                 
Epoch #72: test_reward: 6.183900 ± 1.402954, best_reward: 9.421100 ± 2.851179 in #42
Epoch #73: 100001it [05:43, 291.37it/s, env_step=7300000, len=105, loss=1.508, n/ep=0, n/st=10, rew=3.73]                                                                                                                                                 
Epoch #73: test_reward: 6.137800 ± 1.654983, best_reward: 9.421100 ± 2.851179 in #42
Epoch #74: 100001it [05:45, 289.84it/s, env_step=7400000, len=110, loss=1.555, n/ep=0, n/st=10, rew=3.73]                                                                                                                                                 
Epoch #74: test_reward: 5.881900 ± 1.747907, best_reward: 9.421100 ± 2.851179 in #42
Epoch #75: 100001it [05:43, 290.78it/s, env_step=7500000, len=174, loss=1.608, n/ep=0, n/st=10, rew=7.68]                                                                                                                                                 
Epoch #75: test_reward: 5.844900 ± 1.819892, best_reward: 9.421100 ± 2.851179 in #42
Epoch #76: 100001it [05:43, 290.86it/s, env_step=7600000, len=135, loss=1.633, n/ep=0, n/st=10, rew=6.67]                                                                                                                                                 
Epoch #76: test_reward: 6.295700 ± 1.548053, best_reward: 9.421100 ± 2.851179 in #42
Epoch #77: 100001it [05:39, 294.73it/s, env_step=7700000, len=154, loss=1.554, n/ep=0, n/st=10, rew=7.67]                                                                                                                                                 
Epoch #77: test_reward: 6.958700 ± 1.525706, best_reward: 9.421100 ± 2.851179 in #42
Epoch #78: 100001it [05:37, 296.36it/s, env_step=7800000, len=211, loss=1.521, n/ep=0, n/st=10, rew=10.68]                                                                                                                                                
Epoch #78: test_reward: 6.849600 ± 1.690608, best_reward: 9.421100 ± 2.851179 in #42
Epoch #79: 100001it [05:41, 292.79it/s, env_step=7900000, len=165, loss=1.568, n/ep=0, n/st=10, rew=7.69]                                                                                                                                                 
Epoch #79: test_reward: 6.155000 ± 1.834596, best_reward: 9.421100 ± 2.851179 in #42
Epoch #80: 100001it [05:42, 291.71it/s, env_step=8000000, len=112, loss=1.585, n/ep=0, n/st=10, rew=4.76]                                                                                                                                                 
Epoch #80: test_reward: 8.055700 ± 1.741664, best_reward: 9.421100 ± 2.851179 in #42

## DEFEND THE CENTER DQN

Run: 99_20251209_100328

uv run levd.py --algorithm dqn --scenario defend_the_center --train_levels 0 --train_maps 1 --test_levels 0 --test_maps 1 --seed 99 --epoch 80 --step-per-collect 10 --device cuda --batch-size 64

Epoch #1: 100001it [05:14, 317.58it/s, env_step=100000, len=103, loss=0.058, n/ep=0, n/st=10, rew=1.70]                                                                                                                                                   
Epoch #1: test_reward: 1.451200 ± 0.778645, best_reward: 1.451200 ± 0.778645 in #1
Epoch #2: 100001it [05:15, 317.03it/s, env_step=200000, len=62, loss=0.073, n/ep=0, n/st=10, rew=-0.16]                                                                                                                                                   
Epoch #2: test_reward: 4.170100 ± 0.931431, best_reward: 4.170100 ± 0.931431 in #2
Epoch #3: 100001it [05:16, 315.94it/s, env_step=300000, len=70, loss=0.077, n/ep=0, n/st=10, rew=0.81]                                                                                                                                                    
Epoch #3: test_reward: 1.342000 ± 0.683551, best_reward: 4.170100 ± 0.931431 in #2
Epoch #4: 100001it [05:15, 316.60it/s, env_step=400000, len=74, loss=0.084, n/ep=0, n/st=10, rew=1.80]                                                                                                                                                    
Epoch #4: test_reward: 3.161200 ± 1.145427, best_reward: 4.170100 ± 0.931431 in #2
Epoch #5: 100001it [05:15, 316.49it/s, env_step=500000, len=87, loss=0.079, n/ep=0, n/st=10, rew=1.76]                                                                                                                                                    
Epoch #5: test_reward: 2.805700 ± 1.259772, best_reward: 4.170100 ± 0.931431 in #2
Epoch #6: 100001it [05:15, 316.70it/s, env_step=600000, len=192, loss=0.081, n/ep=0, n/st=10, rew=5.67]                                                                                                                                                   
Epoch #6: test_reward: 4.112000 ± 1.561717, best_reward: 4.170100 ± 0.931431 in #2
Epoch #7: 100001it [05:14, 317.75it/s, env_step=700000, len=101, loss=0.089, n/ep=0, n/st=10, rew=2.72]                                                                                                                                                   
Epoch #7: test_reward: 2.691800 ± 1.399653, best_reward: 4.170100 ± 0.931431 in #2
Epoch #8: 100001it [05:15, 317.25it/s, env_step=800000, len=126, loss=0.092, n/ep=0, n/st=10, rew=4.65]                                                                                                                                                   
Epoch #8: test_reward: 4.484600 ± 1.234383, best_reward: 4.484600 ± 1.234383 in #8
Epoch #9: 100001it [05:15, 317.30it/s, env_step=900000, len=203, loss=0.104, n/ep=0, n/st=10, rew=7.68]                                                                                                                                                   
Epoch #9: test_reward: 6.216500 ± 2.025244, best_reward: 6.216500 ± 2.025244 in #9
Epoch #10: 100001it [05:15, 317.10it/s, env_step=1000000, len=140, loss=0.103, n/ep=0, n/st=10, rew=6.69]                                                                                                                                                 
Epoch #10: test_reward: 5.759500 ± 1.338984, best_reward: 6.216500 ± 2.025244 in #9
Epoch #11: 100001it [05:14, 317.67it/s, env_step=1100000, len=98, loss=0.108, n/ep=0, n/st=10, rew=1.73]                                                                                                                                                  
Epoch #11: test_reward: 4.086000 ± 1.828369, best_reward: 6.216500 ± 2.025244 in #9
Epoch #12: 100001it [05:16, 316.42it/s, env_step=1200000, len=84, loss=0.108, n/ep=0, n/st=10, rew=1.74]                                                                                                                                                  
Epoch #12: test_reward: 2.073800 ± 0.898422, best_reward: 6.216500 ± 2.025244 in #9
Epoch #13: 100001it [05:14, 317.51it/s, env_step=1300000, len=134, loss=0.109, n/ep=0, n/st=10, rew=5.64]                                                                                                                                                 
Epoch #13: test_reward: 5.882400 ± 1.526640, best_reward: 6.216500 ± 2.025244 in #9
Epoch #14: 100001it [05:13, 318.50it/s, env_step=1400000, len=86, loss=0.107, n/ep=1, n/st=10, rew=0.71]                                                                                                                                                  
Epoch #14: test_reward: 5.043700 ± 1.695544, best_reward: 6.216500 ± 2.025244 in #9
Epoch #15: 100001it [05:14, 318.02it/s, env_step=1500000, len=93, loss=0.103, n/ep=1, n/st=10, rew=2.72]                                                                                                                                                  
Epoch #15: test_reward: 4.036700 ± 1.344039, best_reward: 6.216500 ± 2.025244 in #9
Epoch #16: 100001it [05:16, 316.28it/s, env_step=1600000, len=146, loss=0.100, n/ep=0, n/st=10, rew=6.68]                                                                                                                                                 
Epoch #16: test_reward: 6.874600 ± 1.359812, best_reward: 6.874600 ± 1.359812 in #16
Epoch #17: 100001it [05:14, 318.11it/s, env_step=1700000, len=124, loss=0.099, n/ep=0, n/st=10, rew=6.71]                                                                                                                                                 
Epoch #17: test_reward: 7.830700 ± 1.526514, best_reward: 7.830700 ± 1.526514 in #17
Epoch #18: 100001it [05:13, 318.73it/s, env_step=1800000, len=150, loss=0.105, n/ep=0, n/st=10, rew=6.68]                                                                                                                                                 
Epoch #18: test_reward: 5.678800 ± 1.295743, best_reward: 7.830700 ± 1.526514 in #17
Epoch #19: 100001it [05:14, 318.30it/s, env_step=1900000, len=139, loss=0.095, n/ep=0, n/st=10, rew=7.69]                                                                                                                                                 
Epoch #19: test_reward: 7.723100 ± 1.405169, best_reward: 7.830700 ± 1.526514 in #17
Epoch #20: 100001it [05:12, 319.68it/s, env_step=2000000, len=115, loss=0.097, n/ep=0, n/st=10, rew=4.72]                                                                                                                                                 
Epoch #20: test_reward: 6.861600 ± 1.974061, best_reward: 7.830700 ± 1.526514 in #17
Epoch #21: 100001it [05:13, 319.29it/s, env_step=2100000, len=172, loss=0.095, n/ep=1, n/st=10, rew=7.63]                                                                                                                                                 
Epoch #21: test_reward: 7.677200 ± 1.315402, best_reward: 7.830700 ± 1.526514 in #17
Epoch #22: 100001it [05:12, 319.59it/s, env_step=2200000, len=151, loss=0.095, n/ep=0, n/st=10, rew=6.70]                                                                                                                                                 
Epoch #22: test_reward: 8.741900 ± 1.808154, best_reward: 8.741900 ± 1.808154 in #22
Epoch #23: 100001it [05:12, 319.64it/s, env_step=2300000, len=157, loss=0.093, n/ep=0, n/st=10, rew=9.70]                                                                                                                                                 
Epoch #23: test_reward: 10.465700 ± 2.201837, best_reward: 10.465700 ± 2.201837 in #23
Epoch #24: 100001it [05:13, 319.22it/s, env_step=2400000, len=172, loss=0.104, n/ep=0, n/st=10, rew=7.68]                                                                                                                                                 
Epoch #24: test_reward: 6.842200 ± 2.353476, best_reward: 10.465700 ± 2.201837 in #23
Epoch #25: 100001it [05:13, 318.88it/s, env_step=2500000, len=192, loss=0.107, n/ep=0, n/st=10, rew=8.70]                                                                                                                                                 
Epoch #25: test_reward: 8.739500 ± 3.242562, best_reward: 10.465700 ± 2.201837 in #23
Epoch #26: 100001it [05:12, 319.52it/s, env_step=2600000, len=128, loss=0.106, n/ep=0, n/st=10, rew=5.75]                                                                                                                                                 
Epoch #26: test_reward: 7.655200 ± 2.396488, best_reward: 10.465700 ± 2.201837 in #23
Epoch #27: 100001it [05:13, 319.19it/s, env_step=2700000, len=123, loss=0.111, n/ep=0, n/st=10, rew=5.70]                                                                                                                                                 
Epoch #27: test_reward: 7.263900 ± 1.397080, best_reward: 10.465700 ± 2.201837 in #23
Epoch #28: 100001it [05:14, 318.45it/s, env_step=2800000, len=217, loss=0.113, n/ep=0, n/st=10, rew=9.66]                                                                                                                                                 
Epoch #28: test_reward: 11.415400 ± 3.146671, best_reward: 11.415400 ± 3.146671 in #28
Epoch #29: 100001it [05:13, 319.45it/s, env_step=2900000, len=128, loss=0.114, n/ep=0, n/st=10, rew=5.72]                                                                                                                                                 
Epoch #29: test_reward: 8.602600 ± 2.328745, best_reward: 11.415400 ± 3.146671 in #28
Epoch #30: 100001it [05:12, 319.63it/s, env_step=3000000, len=156, loss=0.123, n/ep=0, n/st=10, rew=9.69]                                                                                                                                                 
Epoch #30: test_reward: 9.821600 ± 2.895023, best_reward: 11.415400 ± 3.146671 in #28
Epoch #31: 100001it [05:12, 319.57it/s, env_step=3100000, len=180, loss=0.117, n/ep=0, n/st=10, rew=8.79]                                                                                                                                                 
Epoch #31: test_reward: 10.582500 ± 3.708308, best_reward: 11.415400 ± 3.146671 in #28
Epoch #32: 100001it [05:12, 319.74it/s, env_step=3200000, len=215, loss=0.120, n/ep=0, n/st=10, rew=10.67]                                                                                                                                                
Epoch #32: test_reward: 12.024800 ± 3.807423, best_reward: 12.024800 ± 3.807423 in #32
Epoch #33: 100001it [05:12, 320.12it/s, env_step=3300000, len=125, loss=0.121, n/ep=0, n/st=10, rew=6.66]                                                                                                                                                 
Epoch #33: test_reward: 9.434400 ± 3.217790, best_reward: 12.024800 ± 3.807423 in #32
Epoch #34: 100001it [05:13, 318.82it/s, env_step=3400000, len=136, loss=0.119, n/ep=1, n/st=10, rew=6.71]                                                                                                                                                 
Epoch #34: test_reward: 5.763100 ± 1.690366, best_reward: 12.024800 ± 3.807423 in #32
Epoch #35: 100001it [05:14, 318.29it/s, env_step=3500000, len=155, loss=0.120, n/ep=0, n/st=10, rew=6.69]                                                                                                                                                 
Epoch #35: test_reward: 5.892900 ± 1.638253, best_reward: 12.024800 ± 3.807423 in #32
Epoch #36: 100001it [05:13, 318.55it/s, env_step=3600000, len=154, loss=0.116, n/ep=0, n/st=10, rew=7.67]                                                                                                                                                 
Epoch #36: test_reward: 5.810800 ± 2.418391, best_reward: 12.024800 ± 3.807423 in #32
Epoch #37: 100001it [05:13, 318.80it/s, env_step=3700000, len=153, loss=0.117, n/ep=0, n/st=10, rew=7.77]                                                                                                                                                 
Epoch #37: test_reward: 7.421800 ± 2.454167, best_reward: 12.024800 ± 3.807423 in #32
Epoch #38: 100001it [05:13, 318.82it/s, env_step=3800000, len=102, loss=0.131, n/ep=0, n/st=10, rew=2.77]                                                                                                                                                 
Epoch #38: test_reward: 9.067300 ± 2.550969, best_reward: 12.024800 ± 3.807423 in #32
Epoch #39: 100001it [05:13, 319.48it/s, env_step=3900000, len=103, loss=0.132, n/ep=0, n/st=10, rew=4.77]                                                                                                                                                 
Epoch #39: test_reward: 7.144700 ± 2.656689, best_reward: 12.024800 ± 3.807423 in #32
Epoch #40: 100001it [05:14, 318.40it/s, env_step=4000000, len=154, loss=0.123, n/ep=0, n/st=10, rew=7.69]                                                                                                                                                 
Epoch #40: test_reward: 7.096100 ± 1.946409, best_reward: 12.024800 ± 3.807423 in #32
Epoch #41: 100001it [05:14, 317.88it/s, env_step=4100000, len=134, loss=0.130, n/ep=0, n/st=10, rew=5.69]                                                                                                                                                 
Epoch #41: test_reward: 7.495000 ± 1.959508, best_reward: 12.024800 ± 3.807423 in #32
Epoch #42: 100001it [05:13, 319.24it/s, env_step=4200000, len=65, loss=0.136, n/ep=0, n/st=10, rew=1.85]                                                                                                                                                  
Epoch #42: test_reward: 7.762900 ± 2.642248, best_reward: 12.024800 ± 3.807423 in #32
Epoch #43: 100001it [05:12, 319.74it/s, env_step=4300000, len=136, loss=0.144, n/ep=0, n/st=10, rew=5.72]                                                                                                                                                 
Epoch #43: test_reward: 8.029100 ± 2.734457, best_reward: 12.024800 ± 3.807423 in #32
Epoch #44: 100001it [05:13, 318.79it/s, env_step=4400000, len=195, loss=0.147, n/ep=0, n/st=10, rew=10.70]                                                                                                                                                
Epoch #44: test_reward: 5.923100 ± 2.877734, best_reward: 12.024800 ± 3.807423 in #32
Epoch #45: 100001it [05:13, 319.09it/s, env_step=4500000, len=114, loss=0.160, n/ep=0, n/st=10, rew=3.86]                                                                                                                                                 
Epoch #45: test_reward: 3.549600 ± 2.041395, best_reward: 12.024800 ± 3.807423 in #32
Epoch #46: 100001it [05:13, 318.57it/s, env_step=4600000, len=121, loss=0.166, n/ep=0, n/st=10, rew=4.72]                                                                                                                                                 
Epoch #46: test_reward: 7.135500 ± 2.175611, best_reward: 12.024800 ± 3.807423 in #32
Epoch #47: 100001it [05:13, 318.95it/s, env_step=4700000, len=118, loss=0.160, n/ep=0, n/st=10, rew=3.76]                                                                                                                                                 
Epoch #47: test_reward: 5.164400 ± 2.208175, best_reward: 12.024800 ± 3.807423 in #32
Epoch #48: 100001it [05:13, 318.91it/s, env_step=4800000, len=78, loss=0.184, n/ep=0, n/st=10, rew=1.85]                                                                                                                                                  
Epoch #48: test_reward: 7.559600 ± 2.481824, best_reward: 12.024800 ± 3.807423 in #32
Epoch #49: 100001it [05:14, 317.48it/s, env_step=4900000, len=150, loss=0.191, n/ep=0, n/st=10, rew=7.70]                                                                                                                                                 
Epoch #49: test_reward: 5.407400 ± 2.426964, best_reward: 12.024800 ± 3.807423 in #32
Epoch #50: 100001it [05:13, 318.54it/s, env_step=5000000, len=132, loss=0.184, n/ep=0, n/st=10, rew=5.68]                                                                                                                                                 
Epoch #50: test_reward: 3.899700 ± 2.232029, best_reward: 12.024800 ± 3.807423 in #32
Epoch #51: 100001it [05:13, 318.65it/s, env_step=5100000, len=172, loss=0.188, n/ep=0, n/st=10, rew=7.70]                                                                                                                                                 
Epoch #51: test_reward: 5.070200 ± 2.427103, best_reward: 12.024800 ± 3.807423 in #32
Epoch #52: 100001it [05:13, 318.82it/s, env_step=5200000, len=105, loss=0.182, n/ep=0, n/st=10, rew=6.74]                                                                                                                                                 
Epoch #52: test_reward: 5.667300 ± 2.776208, best_reward: 12.024800 ± 3.807423 in #32
Epoch #53: 100001it [05:14, 318.25it/s, env_step=5300000, len=69, loss=0.176, n/ep=0, n/st=10, rew=2.85]                                                                                                                                                  
Epoch #53: test_reward: 3.204900 ± 1.831649, best_reward: 12.024800 ± 3.807423 in #32
Epoch #54: 100001it [05:13, 318.67it/s, env_step=5400000, len=82, loss=0.166, n/ep=0, n/st=10, rew=2.87]                                                                                                                                                  
Epoch #54: test_reward: 5.489900 ± 2.123269, best_reward: 12.024800 ± 3.807423 in #32
Epoch #55: 100001it [05:13, 318.71it/s, env_step=5500000, len=140, loss=0.162, n/ep=0, n/st=10, rew=6.69]                                                                                                                                                 
Epoch #55: test_reward: 5.010400 ± 2.111041, best_reward: 12.024800 ± 3.807423 in #32
Epoch #56: 100001it [05:13, 318.87it/s, env_step=5600000, len=89, loss=0.169, n/ep=0, n/st=10, rew=1.84]                                                                                                                                                  
Epoch #56: test_reward: 7.384000 ± 3.066897, best_reward: 12.024800 ± 3.807423 in #32
Epoch #57: 100001it [05:13, 318.55it/s, env_step=5700000, len=148, loss=0.165, n/ep=0, n/st=10, rew=5.70]                                                                                                                                                 
Epoch #57: test_reward: 6.014900 ± 2.424622, best_reward: 12.024800 ± 3.807423 in #32
Epoch #58: 100001it [05:14, 318.31it/s, env_step=5800000, len=71, loss=0.166, n/ep=0, n/st=10, rew=0.88]                                                                                                                                                  
Epoch #58: test_reward: 6.041500 ± 2.536882, best_reward: 12.024800 ± 3.807423 in #32
Epoch #59: 100001it [05:13, 318.50it/s, env_step=5900000, len=136, loss=0.157, n/ep=0, n/st=10, rew=7.68]                                                                                                                                                 
Epoch #59: test_reward: 5.150000 ± 2.405165, best_reward: 12.024800 ± 3.807423 in #32
Epoch #60: 100001it [05:14, 318.45it/s, env_step=6000000, len=94, loss=0.161, n/ep=0, n/st=10, rew=1.76]                                                                                                                                                  
Epoch #60: test_reward: 4.943600 ± 1.893176, best_reward: 12.024800 ± 3.807423 in #32
Epoch #61: 100001it [05:14, 318.04it/s, env_step=6100000, len=83, loss=0.162, n/ep=0, n/st=10, rew=1.87]                                                                                                                                                  
Epoch #61: test_reward: 6.620000 ± 3.105965, best_reward: 12.024800 ± 3.807423 in #32
Epoch #62: 100001it [05:13, 318.66it/s, env_step=6200000, len=155, loss=0.147, n/ep=0, n/st=10, rew=6.67]                                                                                                                                                 
Epoch #62: test_reward: 6.102900 ± 2.279859, best_reward: 12.024800 ± 3.807423 in #32
Epoch #63: 100001it [05:13, 319.08it/s, env_step=6300000, len=131, loss=0.141, n/ep=0, n/st=10, rew=4.69]                                                                                                                                                 
Epoch #63: test_reward: 4.872200 ± 1.921490, best_reward: 12.024800 ± 3.807423 in #32
Epoch #64: 100001it [05:13, 318.57it/s, env_step=6400000, len=156, loss=0.139, n/ep=0, n/st=10, rew=6.66]                                                                                                                                                 
Epoch #64: test_reward: 6.552300 ± 1.481162, best_reward: 12.024800 ± 3.807423 in #32
Epoch #65: 100001it [05:13, 318.74it/s, env_step=6500000, len=133, loss=0.132, n/ep=0, n/st=10, rew=5.66]                                                                                                                                                 
Epoch #65: test_reward: 6.552000 ± 2.162956, best_reward: 12.024800 ± 3.807423 in #32
Epoch #66: 100001it [05:14, 317.98it/s, env_step=6600000, len=139, loss=0.126, n/ep=0, n/st=10, rew=5.69]                                                                                                                                                 
Epoch #66: test_reward: 6.497800 ± 1.962735, best_reward: 12.024800 ± 3.807423 in #32
Epoch #67: 100001it [05:13, 319.03it/s, env_step=6700000, len=155, loss=0.136, n/ep=0, n/st=10, rew=7.69]                                                                                                                                                 
Epoch #67: test_reward: 5.983000 ± 1.763696, best_reward: 12.024800 ± 3.807423 in #32
Epoch #68: 100001it [05:13, 318.80it/s, env_step=6800000, len=187, loss=0.129, n/ep=0, n/st=10, rew=6.66]                                                                                                                                                 
Epoch #68: test_reward: 4.407000 ± 1.759265, best_reward: 12.024800 ± 3.807423 in #32
Epoch #69: 100001it [05:14, 318.35it/s, env_step=6900000, len=122, loss=0.127, n/ep=0, n/st=10, rew=6.75]                                                                                                                                                 
Epoch #69: test_reward: 7.976800 ± 1.708615, best_reward: 12.024800 ± 3.807423 in #32
Epoch #70: 100001it [05:14, 318.26it/s, env_step=7000000, len=100, loss=0.123, n/ep=0, n/st=10, rew=2.77]                                                                                                                                                 
Epoch #70: test_reward: 7.290000 ± 1.682621, best_reward: 12.024800 ± 3.807423 in #32
Epoch #71: 100001it [05:14, 317.68it/s, env_step=7100000, len=126, loss=0.126, n/ep=0, n/st=10, rew=4.75]                                                                                                                                                 
Epoch #71: test_reward: 5.598900 ± 2.077725, best_reward: 12.024800 ± 3.807423 in #32
Epoch #72: 100001it [05:14, 317.74it/s, env_step=7200000, len=106, loss=0.118, n/ep=1, n/st=10, rew=5.69]                                                                                                                                                 
Epoch #72: test_reward: 5.474100 ± 1.921777, best_reward: 12.024800 ± 3.807423 in #32
Epoch #73: 100001it [05:13, 318.76it/s, env_step=7300000, len=90, loss=0.111, n/ep=0, n/st=10, rew=2.76]                                                                                                                                                  
Epoch #73: test_reward: 3.338500 ± 2.088629, best_reward: 12.024800 ± 3.807423 in #32
Epoch #74: 100001it [05:14, 317.81it/s, env_step=7400000, len=125, loss=0.120, n/ep=0, n/st=10, rew=5.68]                                                                                                                                                 
Epoch #74: test_reward: 5.074600 ± 2.174620, best_reward: 12.024800 ± 3.807423 in #32
Epoch #75: 100001it [05:14, 318.14it/s, env_step=7500000, len=183, loss=0.120, n/ep=0, n/st=10, rew=7.63]                                                                                                                                                 
Epoch #75: test_reward: 6.994300 ± 1.766036, best_reward: 12.024800 ± 3.807423 in #32
Epoch #76: 100001it [05:13, 318.73it/s, env_step=7600000, len=139, loss=0.117, n/ep=0, n/st=10, rew=5.68]                                                                                                                                                 
Epoch #76: test_reward: 6.711600 ± 2.168634, best_reward: 12.024800 ± 3.807423 in #32
Epoch #77: 100001it [05:14, 318.31it/s, env_step=7700000, len=126, loss=0.125, n/ep=0, n/st=10, rew=6.66]                                                                                                                                                 
Epoch #77: test_reward: 6.490100 ± 1.792820, best_reward: 12.024800 ± 3.807423 in #32
Epoch #78: 100001it [05:13, 319.40it/s, env_step=7800000, len=159, loss=0.116, n/ep=0, n/st=10, rew=6.70]                                                                                                                                                 
Epoch #78: test_reward: 5.775700 ± 2.298231, best_reward: 12.024800 ± 3.807423 in #32
Epoch #79: 100001it [05:14, 318.36it/s, env_step=7900000, len=148, loss=0.119, n/ep=0, n/st=10, rew=6.70]                                                                                                                                                 
Epoch #79: test_reward: 6.546100 ± 1.590257, best_reward: 12.024800 ± 3.807423 in #32
Epoch #80: 100001it [05:14, 317.98it/s, env_step=8000000, len=159, loss=0.123, n/ep=0, n/st=10, rew=7.68]                                                                                                                                                 
Epoch #80: test_reward: 7.804800 ± 2.365014, best_reward: 12.024800 ± 3.807423 in #32
{'best_result': '12.02 ± 3.81',
 'best_reward': 12.024800000000003,
 'duration': '26559.34s',
 'test_episode': 8100,
 'test_speed': '791.57 step/s',
 'test_step': 1135512,
 'test_time': '1434.50s',
 'train_episode': 63541,
 'train_speed': '318.41 step/s',
 'train_step': 8000000,
 'train_time/collector': '11616.22s',
 'train_time/model': '13508.62s'}

## DEFEND THE CENTER DRQN

Run: 99_20251209_231057

uv run levd.py --algorithm drqn --scenario defend_the_center --train_levels 0 --train_maps 1 --test_levels 0 --test_maps 1 --seed 99 --epoch 80 --step-per-collect 10 --device cuda --batch-size 64

Epoch #1: 100001it [05:52, 283.57it/s, env_step=100000, len=76, loss=0.050, n/ep=0, n/st=10, rew=2.79]                                                                                                                                                    
Epoch #1: test_reward: 6.316000 ± 0.985922, best_reward: 6.316000 ± 0.985922 in #1
Epoch #2: 100001it [05:56, 280.61it/s, env_step=200000, len=100, loss=0.058, n/ep=0, n/st=10, rew=2.73]                                                                                                                                                   
Epoch #2: test_reward: 5.742200 ± 1.168863, best_reward: 6.316000 ± 0.985922 in #1
Epoch #3: 100001it [05:55, 281.19it/s, env_step=300000, len=71, loss=0.096, n/ep=0, n/st=10, rew=-0.21]                                                                                                                                                   
Epoch #3: test_reward: 5.201000 ± 1.076647, best_reward: 6.316000 ± 0.985922 in #1
Epoch #4: 100001it [05:54, 281.86it/s, env_step=400000, len=83, loss=0.091, n/ep=0, n/st=10, rew=1.78]                                                                                                                                                    
Epoch #4: test_reward: 4.763900 ± 1.734450, best_reward: 6.316000 ± 0.985922 in #1
Epoch #5: 100001it [05:51, 284.37it/s, env_step=500000, len=137, loss=0.118, n/ep=0, n/st=10, rew=4.66]                                                                                                                                                   
Epoch #5: test_reward: 5.381900 ± 2.246069, best_reward: 6.316000 ± 0.985922 in #1
Epoch #6: 100001it [05:50, 285.16it/s, env_step=600000, len=198, loss=0.182, n/ep=0, n/st=10, rew=7.69]                                                                                                                                                   
Epoch #6: test_reward: 5.481000 ± 1.425683, best_reward: 6.316000 ± 0.985922 in #1
Epoch #7: 100001it [05:50, 285.42it/s, env_step=700000, len=112, loss=0.268, n/ep=0, n/st=10, rew=2.67]                                                                                                                                                   
Epoch #7: test_reward: 3.773500 ± 1.789215, best_reward: 6.316000 ± 0.985922 in #1
Epoch #8: 100001it [05:50, 285.05it/s, env_step=800000, len=79, loss=0.341, n/ep=0, n/st=10, rew=1.78]                                                                                                                                                    
Epoch #8: test_reward: 4.643200 ± 1.224645, best_reward: 6.316000 ± 0.985922 in #1
Epoch #9: 100001it [05:50, 285.49it/s, env_step=900000, len=135, loss=0.417, n/ep=0, n/st=10, rew=5.65]                                                                                                                                                   
Epoch #9: test_reward: 4.333900 ± 1.717283, best_reward: 6.316000 ± 0.985922 in #1
Epoch #10: 100001it [05:50, 285.58it/s, env_step=1000000, len=143, loss=0.486, n/ep=0, n/st=10, rew=5.69]                                                                                                                                                 
Epoch #10: test_reward: 4.132300 ± 1.134855, best_reward: 6.316000 ± 0.985922 in #1
Epoch #11: 100001it [05:49, 285.88it/s, env_step=1100000, len=110, loss=0.628, n/ep=0, n/st=10, rew=4.74]                                                                                                                                                 
Epoch #11: test_reward: 4.872600 ± 1.401890, best_reward: 6.316000 ± 0.985922 in #1
Epoch #12: 100001it [05:50, 285.46it/s, env_step=1200000, len=128, loss=0.605, n/ep=0, n/st=10, rew=3.72]                                                                                                                                                 
Epoch #12: test_reward: 6.202300 ± 2.751718, best_reward: 6.316000 ± 0.985922 in #1
Epoch #13: 100001it [05:49, 285.99it/s, env_step=1300000, len=82, loss=0.683, n/ep=0, n/st=10, rew=1.75]                                                                                                                                                  
Epoch #13: test_reward: 3.095700 ± 1.402896, best_reward: 6.316000 ± 0.985922 in #1
Epoch #14: 100001it [05:49, 285.99it/s, env_step=1400000, len=101, loss=0.792, n/ep=1, n/st=10, rew=5.73]                                                                                                                                                 
Epoch #14: test_reward: 4.602400 ± 1.555233, best_reward: 6.316000 ± 0.985922 in #1
Epoch #15: 100001it [05:50, 285.26it/s, env_step=1500000, len=53, loss=0.818, n/ep=0, n/st=10, rew=-0.15]                                                                                                                                                 
Epoch #15: test_reward: 3.640600 ± 1.435300, best_reward: 6.316000 ± 0.985922 in #1
Epoch #16: 100001it [05:51, 284.66it/s, env_step=1600000, len=115, loss=1.084, n/ep=1, n/st=10, rew=2.70]                                                                                                                                                 
Epoch #16: test_reward: 2.694100 ± 1.246568, best_reward: 6.316000 ± 0.985922 in #1
Epoch #17: 100001it [05:50, 285.14it/s, env_step=1700000, len=71, loss=1.079, n/ep=0, n/st=10, rew=1.77]                                                                                                                                                  
Epoch #17: test_reward: 2.219900 ± 1.256326, best_reward: 6.316000 ± 0.985922 in #1
Epoch #18: 100001it [05:51, 284.84it/s, env_step=1800000, len=108, loss=0.975, n/ep=0, n/st=10, rew=3.71]                                                                                                                                                 
Epoch #18: test_reward: 3.235700 ± 1.446176, best_reward: 6.316000 ± 0.985922 in #1
Epoch #19: 100001it [05:50, 285.28it/s, env_step=1900000, len=82, loss=1.109, n/ep=0, n/st=10, rew=1.79]                                                                                                                                                  
Epoch #19: test_reward: 2.878600 ± 1.587736, best_reward: 6.316000 ± 0.985922 in #1
Epoch #20: 100001it [05:50, 285.17it/s, env_step=2000000, len=104, loss=1.253, n/ep=0, n/st=10, rew=3.77]                                                                                                                                                 
Epoch #20: test_reward: 3.082000 ± 1.478972, best_reward: 6.316000 ± 0.985922 in #1
Epoch #21: 100001it [05:50, 285.35it/s, env_step=2100000, len=146, loss=1.388, n/ep=0, n/st=10, rew=4.69]                                                                                                                                                 
Epoch #21: test_reward: 3.426300 ± 1.120549, best_reward: 6.316000 ± 0.985922 in #1
Epoch #22: 100001it [05:51, 284.89it/s, env_step=2200000, len=66, loss=1.158, n/ep=0, n/st=10, rew=0.82]                                                                                                                                                  
Epoch #22: test_reward: 3.591100 ± 1.275769, best_reward: 6.316000 ± 0.985922 in #1
Epoch #23: 100001it [05:50, 285.41it/s, env_step=2300000, len=143, loss=1.310, n/ep=0, n/st=10, rew=4.67]                                                                                                                                                 
Epoch #23: test_reward: 3.921100 ± 1.622033, best_reward: 6.316000 ± 0.985922 in #1
Epoch #24: 100001it [05:50, 285.01it/s, env_step=2400000, len=124, loss=1.326, n/ep=0, n/st=10, rew=5.68]                                                                                                                                                 
Epoch #24: test_reward: 4.215000 ± 1.344549, best_reward: 6.316000 ± 0.985922 in #1
Epoch #25: 100001it [05:50, 285.12it/s, env_step=2500000, len=132, loss=1.523, n/ep=0, n/st=10, rew=6.62]                                                                                                                                                 
Epoch #25: test_reward: 4.416900 ± 1.435642, best_reward: 6.316000 ± 0.985922 in #1
Epoch #26: 100001it [05:50, 285.48it/s, env_step=2600000, len=117, loss=1.498, n/ep=0, n/st=10, rew=3.70]                                                                                                                                                 
Epoch #26: test_reward: 3.266100 ± 1.183290, best_reward: 6.316000 ± 0.985922 in #1
Epoch #27: 100001it [05:49, 285.96it/s, env_step=2700000, len=142, loss=1.599, n/ep=1, n/st=10, rew=6.70]                                                                                                                                                 
Epoch #27: test_reward: 4.627100 ± 1.484262, best_reward: 6.316000 ± 0.985922 in #1
Epoch #28: 100001it [05:50, 285.58it/s, env_step=2800000, len=76, loss=1.541, n/ep=0, n/st=10, rew=2.81]                                                                                                                                                  
Epoch #28: test_reward: 3.993200 ± 1.818872, best_reward: 6.316000 ± 0.985922 in #1
Epoch #29: 100001it [05:50, 285.64it/s, env_step=2900000, len=155, loss=1.275, n/ep=1, n/st=10, rew=8.66]                                                                                                                                                 
Epoch #29: test_reward: 4.278400 ± 1.735065, best_reward: 6.316000 ± 0.985922 in #1
Epoch #30: 100001it [05:50, 285.53it/s, env_step=3000000, len=131, loss=1.568, n/ep=0, n/st=10, rew=4.69]                                                                                                                                                 
Epoch #30: test_reward: 4.566700 ± 1.745182, best_reward: 6.316000 ± 0.985922 in #1
Epoch #31: 100001it [05:49, 285.82it/s, env_step=3100000, len=133, loss=1.408, n/ep=0, n/st=10, rew=5.69]                                                                                                                                                 
Epoch #31: test_reward: 3.403400 ± 1.925111, best_reward: 6.316000 ± 0.985922 in #1
Epoch #32: 100001it [05:50, 285.60it/s, env_step=3200000, len=138, loss=1.350, n/ep=0, n/st=10, rew=6.66]                                                                                                                                                 
Epoch #32: test_reward: 4.224000 ± 1.511115, best_reward: 6.316000 ± 0.985922 in #1
Epoch #33: 100001it [05:49, 285.88it/s, env_step=3300000, len=156, loss=1.494, n/ep=0, n/st=10, rew=6.64]                                                                                                                                                 
Epoch #33: test_reward: 3.631300 ± 1.593139, best_reward: 6.316000 ± 0.985922 in #1
Epoch #34: 100001it [05:50, 285.35it/s, env_step=3400000, len=126, loss=1.420, n/ep=0, n/st=10, rew=3.69]                                                                                                                                                 
Epoch #34: test_reward: 3.628400 ± 1.637679, best_reward: 6.316000 ± 0.985922 in #1
Epoch #35: 100001it [05:50, 285.54it/s, env_step=3500000, len=99, loss=1.592, n/ep=0, n/st=10, rew=1.74]                                                                                                                                                  
Epoch #35: test_reward: 4.335300 ± 1.784625, best_reward: 6.316000 ± 0.985922 in #1
Epoch #36: 100001it [05:50, 285.68it/s, env_step=3600000, len=118, loss=1.372, n/ep=0, n/st=10, rew=3.68]                                                                                                                                                 
Epoch #36: test_reward: 4.132200 ± 1.271957, best_reward: 6.316000 ± 0.985922 in #1
Epoch #37: 100001it [05:50, 285.21it/s, env_step=3700000, len=113, loss=1.325, n/ep=0, n/st=10, rew=1.65]                                                                                                                                                 
Epoch #37: test_reward: 3.841400 ± 1.221124, best_reward: 6.316000 ± 0.985922 in #1
Epoch #38: 100001it [05:51, 284.79it/s, env_step=3800000, len=141, loss=1.563, n/ep=0, n/st=10, rew=5.60]                                                                                                                                                 
Epoch #38: test_reward: 3.893300 ± 1.622476, best_reward: 6.316000 ± 0.985922 in #1
Epoch #39: 100001it [05:49, 285.79it/s, env_step=3900000, len=135, loss=1.390, n/ep=0, n/st=10, rew=5.65]                                                                                                                                                 
Epoch #39: test_reward: 3.891200 ± 1.035193, best_reward: 6.316000 ± 0.985922 in #1
Epoch #40: 100001it [05:49, 286.00it/s, env_step=4000000, len=134, loss=1.434, n/ep=0, n/st=10, rew=3.67]                                                                                                                                                 
Epoch #40: test_reward: 3.784900 ± 1.166927, best_reward: 6.316000 ± 0.985922 in #1
Epoch #41: 100001it [05:50, 285.60it/s, env_step=4100000, len=131, loss=1.125, n/ep=0, n/st=10, rew=6.72]                                                                                                                                                 
Epoch #41: test_reward: 4.420500 ± 0.972210, best_reward: 6.316000 ± 0.985922 in #1
Epoch #42: 100001it [05:50, 285.58it/s, env_step=4200000, len=118, loss=1.309, n/ep=0, n/st=10, rew=2.74]                                                                                                                                                 
Epoch #42: test_reward: 3.850400 ± 1.469894, best_reward: 6.316000 ± 0.985922 in #1
Epoch #43: 100001it [05:50, 285.58it/s, env_step=4300000, len=121, loss=1.375, n/ep=0, n/st=10, rew=3.68]                                                                                                                                                 
Epoch #43: test_reward: 3.614800 ± 1.951687, best_reward: 6.316000 ± 0.985922 in #1
Epoch #44: 100001it [05:50, 285.28it/s, env_step=4400000, len=100, loss=1.153, n/ep=0, n/st=10, rew=2.77]                                                                                                                                                 
Epoch #44: test_reward: 4.319700 ± 1.099566, best_reward: 6.316000 ± 0.985922 in #1
Epoch #45: 100001it [05:51, 284.86it/s, env_step=4500000, len=106, loss=1.397, n/ep=0, n/st=10, rew=2.68]                                                                                                                                                 
Epoch #45: test_reward: 1.162400 ± 1.146387, best_reward: 6.316000 ± 0.985922 in #1
Epoch #46: 100001it [05:50, 285.40it/s, env_step=4600000, len=119, loss=1.372, n/ep=0, n/st=10, rew=2.66]                                                                                                                                                 
Epoch #46: test_reward: 3.885800 ± 1.528393, best_reward: 6.316000 ± 0.985922 in #1
Epoch #47: 100001it [05:50, 285.34it/s, env_step=4700000, len=113, loss=1.422, n/ep=0, n/st=10, rew=3.69]                                                                                                                                                 
Epoch #47: test_reward: 4.474200 ± 1.296551, best_reward: 6.316000 ± 0.985922 in #1
Epoch #48: 100001it [05:50, 285.66it/s, env_step=4800000, len=110, loss=1.403, n/ep=0, n/st=10, rew=2.69]                                                                                                                                                 
Epoch #48: test_reward: 4.355700 ± 1.472904, best_reward: 6.316000 ± 0.985922 in #1
Epoch #49: 100001it [05:50, 285.44it/s, env_step=4900000, len=94, loss=1.382, n/ep=0, n/st=10, rew=1.71]                                                                                                                                                  
Epoch #49: test_reward: 2.654600 ± 1.092926, best_reward: 6.316000 ± 0.985922 in #1
Epoch #50: 100001it [05:50, 285.19it/s, env_step=5000000, len=110, loss=1.292, n/ep=0, n/st=10, rew=2.65]                                                                                                                                                 
Epoch #50: test_reward: 3.896500 ± 1.140300, best_reward: 6.316000 ± 0.985922 in #1
Epoch #51: 100001it [05:50, 285.69it/s, env_step=5100000, len=77, loss=1.226, n/ep=0, n/st=10, rew=3.80]                                                                                                                                                  
Epoch #51: test_reward: 4.195200 ± 1.294824, best_reward: 6.316000 ± 0.985922 in #1
Epoch #52: 100001it [05:50, 285.18it/s, env_step=5200000, len=124, loss=1.515, n/ep=0, n/st=10, rew=2.62]                                                                                                                                                 
Epoch #52: test_reward: 4.028500 ± 1.328521, best_reward: 6.316000 ± 0.985922 in #1
Epoch #53: 100001it [05:50, 285.52it/s, env_step=5300000, len=129, loss=1.283, n/ep=0, n/st=10, rew=4.73]                                                                                                                                                 
Epoch #53: test_reward: 3.995300 ± 1.177023, best_reward: 6.316000 ± 0.985922 in #1
Epoch #54: 100001it [05:50, 285.46it/s, env_step=5400000, len=112, loss=1.360, n/ep=0, n/st=10, rew=4.67]                                                                                                                                                 
Epoch #54: test_reward: 4.068400 ± 1.409264, best_reward: 6.316000 ± 0.985922 in #1
Epoch #55: 100001it [05:50, 285.23it/s, env_step=5500000, len=101, loss=1.233, n/ep=0, n/st=10, rew=2.74]                                                                                                                                                 
Epoch #55: test_reward: 4.206100 ± 1.309555, best_reward: 6.316000 ± 0.985922 in #1
Epoch #56: 100001it [05:50, 285.54it/s, env_step=5600000, len=111, loss=1.202, n/ep=0, n/st=10, rew=3.65]                                                                                                                                                 
Epoch #56: test_reward: 3.811300 ± 1.405811, best_reward: 6.316000 ± 0.985922 in #1
Epoch #57: 100001it [05:50, 285.17it/s, env_step=5700000, len=86, loss=1.156, n/ep=0, n/st=10, rew=3.81]                                                                                                                                                  
Epoch #57: test_reward: 4.765100 ± 1.331939, best_reward: 6.316000 ± 0.985922 in #1
Epoch #58: 100001it [05:50, 285.17it/s, env_step=5800000, len=126, loss=1.217, n/ep=0, n/st=10, rew=3.68]                                                                                                                                                 
Epoch #58: test_reward: 4.226200 ± 1.345345, best_reward: 6.316000 ± 0.985922 in #1
Epoch #59: 100001it [05:50, 285.31it/s, env_step=5900000, len=107, loss=1.256, n/ep=0, n/st=10, rew=2.68]                                                                                                                                                 
Epoch #59: test_reward: 3.930900 ± 1.206544, best_reward: 6.316000 ± 0.985922 in #1
Epoch #60: 100001it [05:50, 284.97it/s, env_step=6000000, len=133, loss=1.038, n/ep=0, n/st=10, rew=3.65]                                                                                                                                                 
Epoch #60: test_reward: 3.995600 ± 1.052685, best_reward: 6.316000 ± 0.985922 in #1
Epoch #61: 100001it [05:50, 285.19it/s, env_step=6100000, len=113, loss=0.934, n/ep=0, n/st=10, rew=3.66]                                                                                                                                                 
Epoch #61: test_reward: 4.644200 ± 1.344160, best_reward: 6.316000 ± 0.985922 in #1
Epoch #62: 100001it [05:50, 285.18it/s, env_step=6200000, len=141, loss=1.129, n/ep=0, n/st=10, rew=5.69]                                                                                                                                                 
Epoch #62: test_reward: 4.265300 ± 1.347424, best_reward: 6.316000 ± 0.985922 in #1
Epoch #63: 100001it [05:50, 285.07it/s, env_step=6300000, len=120, loss=1.065, n/ep=0, n/st=10, rew=3.69]                                                                                                                                                 
Epoch #63: test_reward: 4.152400 ± 1.134863, best_reward: 6.316000 ± 0.985922 in #1
Epoch #64: 100001it [05:50, 285.27it/s, env_step=6400000, len=125, loss=1.116, n/ep=1, n/st=10, rew=4.67]                                                                                                                                                 
Epoch #64: test_reward: 4.651500 ± 1.114073, best_reward: 6.316000 ± 0.985922 in #1
Epoch #65: 100001it [05:50, 285.65it/s, env_step=6500000, len=155, loss=0.959, n/ep=1, n/st=10, rew=7.69]                                                                                                                                                 
Epoch #65: test_reward: 3.936100 ± 1.425643, best_reward: 6.316000 ± 0.985922 in #1
Epoch #66: 100001it [05:51, 284.89it/s, env_step=6600000, len=172, loss=0.982, n/ep=0, n/st=10, rew=6.68]                                                                                                                                                 
Epoch #66: test_reward: 3.466900 ± 1.308181, best_reward: 6.316000 ± 0.985922 in #1
Epoch #67: 100001it [05:50, 285.00it/s, env_step=6700000, len=57, loss=1.163, n/ep=0, n/st=10, rew=-0.13]                                                                                                                                                 
Epoch #67: test_reward: 3.056200 ± 1.552253, best_reward: 6.316000 ± 0.985922 in #1
Epoch #68: 100001it [05:50, 285.43it/s, env_step=6800000, len=118, loss=0.976, n/ep=0, n/st=10, rew=4.69]                                                                                                                                                 
Epoch #68: test_reward: 4.562500 ± 1.443354, best_reward: 6.316000 ± 0.985922 in #1
Epoch #69: 100001it [05:50, 285.26it/s, env_step=6900000, len=106, loss=0.930, n/ep=0, n/st=10, rew=3.70]                                                                                                                                                 
Epoch #69: test_reward: 3.682400 ± 1.228335, best_reward: 6.316000 ± 0.985922 in #1
Epoch #70: 100001it [05:50, 285.06it/s, env_step=7000000, len=114, loss=1.012, n/ep=0, n/st=10, rew=3.70]                                                                                                                                                 
Epoch #70: test_reward: 2.521800 ± 1.520907, best_reward: 6.316000 ± 0.985922 in #1
Epoch #71: 100001it [05:50, 285.43it/s, env_step=7100000, len=133, loss=1.032, n/ep=0, n/st=10, rew=5.70]                                                                                                                                                 
Epoch #71: test_reward: 3.629100 ± 1.494299, best_reward: 6.316000 ± 0.985922 in #1
Epoch #72: 100001it [05:50, 285.25it/s, env_step=7200000, len=110, loss=1.000, n/ep=0, n/st=10, rew=3.68]                                                                                                                                                 
Epoch #72: test_reward: 3.051300 ± 1.249039, best_reward: 6.316000 ± 0.985922 in #1
Epoch #73: 100001it [05:50, 285.10it/s, env_step=7300000, len=121, loss=0.943, n/ep=0, n/st=10, rew=4.68]                                                                                                                                                 
Epoch #73: test_reward: 4.354300 ± 1.930504, best_reward: 6.316000 ± 0.985922 in #1
Epoch #74: 100001it [05:50, 285.31it/s, env_step=7400000, len=110, loss=0.977, n/ep=0, n/st=10, rew=1.68]                                                                                                                                                 
Epoch #74: test_reward: 2.553100 ± 1.670889, best_reward: 6.316000 ± 0.985922 in #1
Epoch #75: 100001it [05:51, 284.70it/s, env_step=7500000, len=106, loss=0.907, n/ep=0, n/st=10, rew=2.71]                                                                                                                                                 
Epoch #75: test_reward: 2.547100 ± 1.643436, best_reward: 6.316000 ± 0.985922 in #1
Epoch #76: 100001it [05:50, 285.15it/s, env_step=7600000, len=126, loss=0.912, n/ep=0, n/st=10, rew=5.68]                                                                                                                                                 
Epoch #76: test_reward: 3.636800 ± 1.356711, best_reward: 6.316000 ± 0.985922 in #1
Epoch #77: 100001it [05:51, 284.72it/s, env_step=7700000, len=74, loss=0.807, n/ep=0, n/st=10, rew=2.77]                                                                                                                                                  
Epoch #77: test_reward: 3.515100 ± 1.516190, best_reward: 6.316000 ± 0.985922 in #1
Epoch #78: 100001it [05:50, 285.33it/s, env_step=7800000, len=69, loss=0.779, n/ep=0, n/st=10, rew=0.81]                                                                                                                                                  
Epoch #78: test_reward: 2.731700 ± 1.449437, best_reward: 6.316000 ± 0.985922 in #1
Epoch #79: 100001it [05:51, 284.83it/s, env_step=7900000, len=127, loss=0.819, n/ep=0, n/st=10, rew=2.66]                                                                                                                                                 
Epoch #79: test_reward: 1.998800 ± 1.163349, best_reward: 6.316000 ± 0.985922 in #1
Epoch #80: 100001it [05:50, 285.19it/s, env_step=8000000, len=81, loss=0.762, n/ep=0, n/st=10, rew=0.85]                                                                                                                                                  
Epoch #80: test_reward: 3.323700 ± 1.809572, best_reward: 6.316000 ± 0.985922 in #1
{'best_result': '6.32 ± 0.99',
 'best_reward': 6.3160000000000025,
 'duration': '29348.92s',
 'test_episode': 8100,
 'test_speed': '736.26 step/s',
 'test_step': 951398,
 'test_time': '1292.21s',
 'train_episode': 72235,
 'train_speed': '285.14 step/s',
 'train_step': 8000000,
 'train_time/collector': '12412.96s',
 'train_time/model': '15643.75s'}

## DEFEND THE CENTER C51

Run: 99_20251210_093621

uv run levd.py --algorithm c51 --scenario defend_the_center --train_levels 0 --train_maps 1 --test_levels 0 --test_maps 1 --seed 42 --epoch 80 --step-per-collect 10 --device cuda --batch-size 64

Epoch #1: 100001it [05:13, 319.21it/s, env_step=100000, len=76, loss=3.782, n/ep=1, n/st=10, rew=0.79]                                                                                                                                                    
Epoch #1: test_reward: 6.912300 ± 2.128108, best_reward: 6.912300 ± 2.128108 in #1
Epoch #2: 100001it [05:15, 317.28it/s, env_step=200000, len=71, loss=3.672, n/ep=0, n/st=10, rew=0.79]                                                                                                                                                    
Epoch #2: test_reward: 5.633100 ± 2.356966, best_reward: 6.912300 ± 2.128108 in #1
Epoch #3: 100001it [05:14, 317.64it/s, env_step=300000, len=107, loss=3.566, n/ep=0, n/st=10, rew=3.72]                                                                                                                                                   
Epoch #3: test_reward: 6.264000 ± 2.101640, best_reward: 6.912300 ± 2.128108 in #1
Epoch #4: 100001it [05:14, 318.31it/s, env_step=400000, len=102, loss=3.515, n/ep=0, n/st=10, rew=3.69]                                                                                                                                                   
Epoch #4: test_reward: 2.975700 ± 1.411446, best_reward: 6.912300 ± 2.128108 in #1
Epoch #5: 100001it [05:14, 318.42it/s, env_step=500000, len=62, loss=3.414, n/ep=0, n/st=10, rew=0.81]                                                                                                                                                    
Epoch #5: test_reward: 5.757400 ± 1.243385, best_reward: 6.912300 ± 2.128108 in #1
Epoch #6: 100001it [05:14, 318.32it/s, env_step=600000, len=131, loss=3.368, n/ep=0, n/st=10, rew=4.68]                                                                                                                                                   
Epoch #6: test_reward: 5.061600 ± 0.847398, best_reward: 6.912300 ± 2.128108 in #1
Epoch #7: 100001it [05:13, 319.11it/s, env_step=700000, len=163, loss=3.317, n/ep=0, n/st=10, rew=6.68]                                                                                                                                                   
Epoch #7: test_reward: 10.706100 ± 2.411312, best_reward: 10.706100 ± 2.411312 in #7
Epoch #8: 100001it [05:12, 320.26it/s, env_step=800000, len=152, loss=3.299, n/ep=0, n/st=10, rew=6.68]                                                                                                                                                   
Epoch #8: test_reward: 4.112200 ± 0.892507, best_reward: 10.706100 ± 2.411312 in #7
Epoch #9: 100001it [05:13, 318.91it/s, env_step=900000, len=78, loss=3.257, n/ep=0, n/st=10, rew=2.75]                                                                                                                                                    
Epoch #9: test_reward: 3.492300 ± 1.428055, best_reward: 10.706100 ± 2.411312 in #7
Epoch #10: 100001it [05:12, 319.92it/s, env_step=1000000, len=91, loss=3.221, n/ep=0, n/st=10, rew=0.76]                                                                                                                                                  
Epoch #10: test_reward: 6.041800 ± 1.309021, best_reward: 10.706100 ± 2.411312 in #7
Epoch #11: 100001it [05:12, 319.72it/s, env_step=1100000, len=123, loss=3.184, n/ep=0, n/st=10, rew=5.67]                                                                                                                                                 
Epoch #11: test_reward: 6.428300 ± 1.156931, best_reward: 10.706100 ± 2.411312 in #7
Epoch #12: 100001it [05:13, 319.42it/s, env_step=1200000, len=133, loss=3.134, n/ep=0, n/st=10, rew=3.64]                                                                                                                                                 
Epoch #12: test_reward: 3.578000 ± 1.513000, best_reward: 10.706100 ± 2.411312 in #7
Epoch #13: 100001it [05:12, 319.86it/s, env_step=1300000, len=115, loss=3.107, n/ep=0, n/st=10, rew=5.71]                                                                                                                                                 
Epoch #13: test_reward: 6.824400 ± 1.565255, best_reward: 10.706100 ± 2.411312 in #7
Epoch #14: 100001it [05:11, 320.69it/s, env_step=1400000, len=164, loss=3.047, n/ep=0, n/st=10, rew=6.64]                                                                                                                                                 
Epoch #14: test_reward: 4.827500 ± 1.114772, best_reward: 10.706100 ± 2.411312 in #7
Epoch #15: 100001it [05:12, 320.02it/s, env_step=1500000, len=173, loss=2.997, n/ep=0, n/st=10, rew=6.65]                                                                                                                                                 
Epoch #15: test_reward: 6.989000 ± 1.168395, best_reward: 10.706100 ± 2.411312 in #7
Epoch #16: 100001it [05:12, 319.96it/s, env_step=1600000, len=116, loss=2.959, n/ep=0, n/st=10, rew=5.71]                                                                                                                                                 
Epoch #16: test_reward: 7.159800 ± 0.945982, best_reward: 10.706100 ± 2.411312 in #7
Epoch #17: 100001it [05:12, 319.76it/s, env_step=1700000, len=109, loss=2.910, n/ep=1, n/st=10, rew=3.72]                                                                                                                                                 
Epoch #17: test_reward: 6.327700 ± 1.334258, best_reward: 10.706100 ± 2.411312 in #7
Epoch #18: 100001it [05:12, 319.84it/s, env_step=1800000, len=83, loss=2.908, n/ep=1, n/st=10, rew=1.79]                                                                                                                                                  
Epoch #18: test_reward: 2.206000 ± 1.623191, best_reward: 10.706100 ± 2.411312 in #7
Epoch #19: 100001it [05:13, 318.89it/s, env_step=1900000, len=120, loss=2.874, n/ep=0, n/st=10, rew=4.70]                                                                                                                                                 
Epoch #19: test_reward: 2.868500 ± 1.988319, best_reward: 10.706100 ± 2.411312 in #7
Epoch #20: 100001it [05:12, 320.23it/s, env_step=2000000, len=106, loss=2.837, n/ep=0, n/st=10, rew=3.71]                                                                                                                                                 
Epoch #20: test_reward: 5.552700 ± 1.648536, best_reward: 10.706100 ± 2.411312 in #7
Epoch #21: 100001it [05:11, 321.44it/s, env_step=2100000, len=89, loss=2.829, n/ep=0, n/st=10, rew=0.74]                                                                                                                                                  
Epoch #21: test_reward: 2.831300 ± 2.018026, best_reward: 10.706100 ± 2.411312 in #7
Epoch #22: 100001it [05:12, 319.78it/s, env_step=2200000, len=82, loss=2.825, n/ep=0, n/st=10, rew=1.81]                                                                                                                                                  
Epoch #22: test_reward: 3.778100 ± 1.767722, best_reward: 10.706100 ± 2.411312 in #7
Epoch #23: 100001it [05:11, 321.05it/s, env_step=2300000, len=124, loss=2.827, n/ep=0, n/st=10, rew=2.79]                                                                                                                                                 
Epoch #23: test_reward: 1.940100 ± 1.221443, best_reward: 10.706100 ± 2.411312 in #7
Epoch #24: 100001it [05:12, 320.03it/s, env_step=2400000, len=115, loss=2.837, n/ep=0, n/st=10, rew=1.75]                                                                                                                                                 
Epoch #24: test_reward: 4.299500 ± 1.777270, best_reward: 10.706100 ± 2.411312 in #7
Epoch #25: 100001it [05:12, 320.36it/s, env_step=2500000, len=106, loss=2.839, n/ep=1, n/st=10, rew=2.79]                                                                                                                                                 
Epoch #25: test_reward: 4.323100 ± 1.881370, best_reward: 10.706100 ± 2.411312 in #7
Epoch #26: 100001it [05:11, 320.54it/s, env_step=2600000, len=108, loss=2.862, n/ep=0, n/st=10, rew=3.73]                                                                                                                                                 
Epoch #26: test_reward: 5.905300 ± 2.017527, best_reward: 10.706100 ± 2.411312 in #7
Epoch #27: 100001it [05:12, 319.80it/s, env_step=2700000, len=145, loss=2.845, n/ep=0, n/st=10, rew=4.76]                                                                                                                                                 
Epoch #27: test_reward: 5.963400 ± 2.398041, best_reward: 10.706100 ± 2.411312 in #7
Epoch #28: 100001it [05:12, 320.08it/s, env_step=2800000, len=125, loss=2.850, n/ep=0, n/st=10, rew=6.72]                                                                                                                                                 
Epoch #28: test_reward: 6.422600 ± 1.940584, best_reward: 10.706100 ± 2.411312 in #7
Epoch #29: 100001it [05:11, 321.23it/s, env_step=2900000, len=146, loss=2.827, n/ep=0, n/st=10, rew=7.76]                                                                                                                                                 
Epoch #29: test_reward: 9.369400 ± 2.570008, best_reward: 10.706100 ± 2.411312 in #7
Epoch #30: 100001it [05:12, 320.29it/s, env_step=3000000, len=122, loss=2.806, n/ep=0, n/st=10, rew=4.69]                                                                                                                                                 
Epoch #30: test_reward: 7.969600 ± 2.424728, best_reward: 10.706100 ± 2.411312 in #7
Epoch #31: 100001it [05:10, 322.25it/s, env_step=3100000, len=215, loss=2.815, n/ep=0, n/st=10, rew=7.67]                                                                                                                                                 
Epoch #31: test_reward: 8.168600 ± 2.593691, best_reward: 10.706100 ± 2.411312 in #7
Epoch #32: 100001it [05:11, 321.19it/s, env_step=3200000, len=104, loss=2.812, n/ep=1, n/st=10, rew=3.80]                                                                                                                                                 
Epoch #32: test_reward: 8.595300 ± 3.521356, best_reward: 10.706100 ± 2.411312 in #7
Epoch #33: 100001it [05:10, 322.08it/s, env_step=3300000, len=155, loss=2.784, n/ep=0, n/st=10, rew=6.70]                                                                                                                                                 
Epoch #33: test_reward: 7.564300 ± 2.695228, best_reward: 10.706100 ± 2.411312 in #7
Epoch #34: 100001it [05:10, 321.89it/s, env_step=3400000, len=178, loss=2.768, n/ep=0, n/st=10, rew=9.71]                                                                                                                                                 
Epoch #34: test_reward: 8.946100 ± 2.611527, best_reward: 10.706100 ± 2.411312 in #7
Epoch #35: 100001it [05:10, 321.77it/s, env_step=3500000, len=134, loss=2.754, n/ep=1, n/st=10, rew=5.76]                                                                                                                                                 
Epoch #35: test_reward: 2.307900 ± 1.682910, best_reward: 10.706100 ± 2.411312 in #7
Epoch #36: 100001it [05:11, 320.64it/s, env_step=3600000, len=117, loss=2.744, n/ep=0, n/st=10, rew=4.76]                                                                                                                                                 
Epoch #36: test_reward: 8.712000 ± 2.130885, best_reward: 10.706100 ± 2.411312 in #7
Epoch #37: 100001it [05:10, 322.19it/s, env_step=3700000, len=211, loss=2.738, n/ep=0, n/st=10, rew=8.70]                                                                                                                                                 
Epoch #37: test_reward: 9.972900 ± 3.422359, best_reward: 10.706100 ± 2.411312 in #7
Epoch #38: 100001it [05:10, 321.99it/s, env_step=3800000, len=193, loss=2.745, n/ep=0, n/st=10, rew=8.64]                                                                                                                                                 
Epoch #38: test_reward: 9.545000 ± 3.001455, best_reward: 10.706100 ± 2.411312 in #7
Epoch #39: 100001it [05:10, 322.41it/s, env_step=3900000, len=113, loss=2.737, n/ep=0, n/st=10, rew=3.72]                                                                                                                                                 
Epoch #39: test_reward: 7.009800 ± 2.893191, best_reward: 10.706100 ± 2.411312 in #7
Epoch #40: 100001it [05:10, 322.01it/s, env_step=4000000, len=124, loss=2.711, n/ep=1, n/st=10, rew=4.70]                                                                                                                                                 
Epoch #40: test_reward: 7.100200 ± 2.403949, best_reward: 10.706100 ± 2.411312 in #7
Epoch #41: 100001it [05:12, 320.03it/s, env_step=4100000, len=247, loss=2.699, n/ep=0, n/st=10, rew=10.65]                                                                                                                                                
Epoch #41: test_reward: 10.065100 ± 1.635054, best_reward: 10.706100 ± 2.411312 in #7
Epoch #42: 100001it [05:10, 322.13it/s, env_step=4200000, len=139, loss=2.678, n/ep=0, n/st=10, rew=5.65]                                                                                                                                                 
Epoch #42: test_reward: 9.501800 ± 3.147239, best_reward: 10.706100 ± 2.411312 in #7
Epoch #43: 100001it [05:10, 322.50it/s, env_step=4300000, len=159, loss=2.651, n/ep=0, n/st=10, rew=6.65]                                                                                                                                                 
Epoch #43: test_reward: 5.699300 ± 2.830233, best_reward: 10.706100 ± 2.411312 in #7
Epoch #44: 100001it [05:10, 322.24it/s, env_step=4400000, len=194, loss=2.654, n/ep=0, n/st=10, rew=8.70]                                                                                                                                                 
Epoch #44: test_reward: 12.205000 ± 2.535413, best_reward: 12.205000 ± 2.535413 in #44
Epoch #45: 100001it [05:10, 322.20it/s, env_step=4500000, len=193, loss=2.630, n/ep=0, n/st=10, rew=8.68]                                                                                                                                                 
Epoch #45: test_reward: 9.252000 ± 1.592384, best_reward: 12.205000 ± 2.535413 in #44
Epoch #46: 100001it [05:11, 321.06it/s, env_step=4600000, len=152, loss=2.600, n/ep=0, n/st=10, rew=6.68]                                                                                                                                                 
Epoch #46: test_reward: 7.274200 ± 1.704871, best_reward: 12.205000 ± 2.535413 in #44
Epoch #47: 100001it [05:11, 321.47it/s, env_step=4700000, len=144, loss=2.574, n/ep=0, n/st=10, rew=6.67]                                                                                                                                                 
Epoch #47: test_reward: 7.747800 ± 1.431120, best_reward: 12.205000 ± 2.535413 in #44
Epoch #48: 100001it [05:11, 321.14it/s, env_step=4800000, len=206, loss=2.559, n/ep=0, n/st=10, rew=10.70]                                                                                                                                                
Epoch #48: test_reward: 8.420100 ± 2.233794, best_reward: 12.205000 ± 2.535413 in #44
Epoch #49: 100001it [05:11, 321.31it/s, env_step=4900000, len=196, loss=2.569, n/ep=0, n/st=10, rew=9.67]                                                                                                                                                 
Epoch #49: test_reward: 10.638100 ± 3.640342, best_reward: 12.205000 ± 2.535413 in #44
Epoch #50: 100001it [05:11, 321.46it/s, env_step=5000000, len=126, loss=2.555, n/ep=0, n/st=10, rew=6.71]                                                                                                                                                 
Epoch #50: test_reward: 9.671900 ± 2.001328, best_reward: 12.205000 ± 2.535413 in #44
Epoch #51: 100001it [05:10, 322.31it/s, env_step=5100000, len=205, loss=2.550, n/ep=0, n/st=10, rew=9.68]                                                                                                                                                 
Epoch #51: test_reward: 9.793300 ± 2.518504, best_reward: 12.205000 ± 2.535413 in #44
Epoch #52: 100001it [05:10, 322.03it/s, env_step=5200000, len=121, loss=2.545, n/ep=0, n/st=10, rew=5.71]                                                                                                                                                 
Epoch #52: test_reward: 9.981900 ± 1.931401, best_reward: 12.205000 ± 2.535413 in #44
Epoch #53: 100001it [05:12, 319.98it/s, env_step=5300000, len=236, loss=2.543, n/ep=0, n/st=10, rew=12.70]                                                                                                                                                
Epoch #53: test_reward: 15.284100 ± 2.945819, best_reward: 15.284100 ± 2.945819 in #53
Epoch #54: 100001it [05:12, 320.31it/s, env_step=5400000, len=194, loss=2.553, n/ep=0, n/st=10, rew=8.70]                                                                                                                                                 
Epoch #54: test_reward: 8.432700 ± 1.567866, best_reward: 15.284100 ± 2.945819 in #53
Epoch #55: 100001it [05:12, 320.43it/s, env_step=5500000, len=247, loss=2.551, n/ep=0, n/st=10, rew=12.66]                                                                                                                                                
Epoch #55: test_reward: 12.185100 ± 3.274336, best_reward: 15.284100 ± 2.945819 in #53
Epoch #56: 100001it [05:10, 322.16it/s, env_step=5600000, len=212, loss=2.546, n/ep=0, n/st=10, rew=10.65]                                                                                                                                                
Epoch #56: test_reward: 12.285700 ± 2.917890, best_reward: 15.284100 ± 2.945819 in #53
Epoch #57: 100001it [05:10, 321.88it/s, env_step=5700000, len=131, loss=2.544, n/ep=0, n/st=10, rew=7.76]                                                                                                                                                 
Epoch #57: test_reward: 10.369600 ± 2.780541, best_reward: 15.284100 ± 2.945819 in #53
Epoch #58: 100001it [05:11, 320.95it/s, env_step=5800000, len=207, loss=2.529, n/ep=0, n/st=10, rew=9.70]                                                                                                                                                 
Epoch #58: test_reward: 12.480600 ± 3.782694, best_reward: 15.284100 ± 2.945819 in #53
Epoch #59: 100001it [05:10, 321.71it/s, env_step=5900000, len=84, loss=2.511, n/ep=0, n/st=10, rew=3.82]                                                                                                                                                  
Epoch #59: test_reward: 8.653500 ± 1.575811, best_reward: 15.284100 ± 2.945819 in #53
Epoch #60: 100001it [05:11, 320.96it/s, env_step=6000000, len=141, loss=2.493, n/ep=1, n/st=10, rew=5.72]                                                                                                                                                 
Epoch #60: test_reward: 7.940200 ± 1.569463, best_reward: 15.284100 ± 2.945819 in #53
Epoch #61: 100001it [05:11, 321.25it/s, env_step=6100000, len=115, loss=2.492, n/ep=0, n/st=10, rew=2.76]                                                                                                                                                 
Epoch #61: test_reward: 8.708700 ± 1.814133, best_reward: 15.284100 ± 2.945819 in #53
Epoch #62: 100001it [05:10, 322.01it/s, env_step=6200000, len=177, loss=2.477, n/ep=0, n/st=10, rew=7.69]                                                                                                                                                 
Epoch #62: test_reward: 9.018300 ± 2.463558, best_reward: 15.284100 ± 2.945819 in #53
Epoch #63: 100001it [05:10, 322.58it/s, env_step=6300000, len=197, loss=2.468, n/ep=1, n/st=10, rew=8.68]                                                                                                                                                 
Epoch #63: test_reward: 10.072400 ± 1.583958, best_reward: 15.284100 ± 2.945819 in #53
Epoch #64: 100001it [05:10, 322.12it/s, env_step=6400000, len=120, loss=2.459, n/ep=0, n/st=10, rew=5.82]                                                                                                                                                 
Epoch #64: test_reward: 10.671300 ± 2.985852, best_reward: 15.284100 ± 2.945819 in #53
Epoch #65: 100001it [05:09, 323.24it/s, env_step=6500000, len=192, loss=2.462, n/ep=0, n/st=10, rew=8.66]                                                                                                                                                 
Epoch #65: test_reward: 8.517500 ± 2.010239, best_reward: 15.284100 ± 2.945819 in #53
Epoch #66: 100001it [05:10, 322.13it/s, env_step=6600000, len=176, loss=2.449, n/ep=0, n/st=10, rew=7.70]                                                                                                                                                 
Epoch #66: test_reward: 9.034700 ± 2.416028, best_reward: 15.284100 ± 2.945819 in #53
Epoch #67: 100001it [05:10, 322.12it/s, env_step=6700000, len=200, loss=2.442, n/ep=0, n/st=10, rew=8.70]                                                                                                                                                 
Epoch #67: test_reward: 10.034700 ± 2.318301, best_reward: 15.284100 ± 2.945819 in #53
Epoch #68: 100001it [05:12, 320.20it/s, env_step=6800000, len=121, loss=2.444, n/ep=0, n/st=10, rew=3.75]                                                                                                                                                 
Epoch #68: test_reward: 8.525600 ± 2.617994, best_reward: 15.284100 ± 2.945819 in #53
Epoch #69: 100001it [05:10, 322.51it/s, env_step=6900000, len=145, loss=2.452, n/ep=0, n/st=10, rew=6.71]                                                                                                                                                 
Epoch #69: test_reward: 9.002400 ± 3.410320, best_reward: 15.284100 ± 2.945819 in #53
Epoch #70: 100001it [05:10, 322.12it/s, env_step=7000000, len=152, loss=2.442, n/ep=1, n/st=10, rew=6.75]                                                                                                                                                 
Epoch #70: test_reward: 11.147200 ± 3.420732, best_reward: 15.284100 ± 2.945819 in #53
Epoch #71: 100001it [05:11, 320.71it/s, env_step=7100000, len=198, loss=2.460, n/ep=0, n/st=10, rew=10.67]                                                                                                                                                
Epoch #71: test_reward: 10.206900 ± 3.223608, best_reward: 15.284100 ± 2.945819 in #53
Epoch #72: 100001it [05:11, 321.37it/s, env_step=7200000, len=118, loss=2.460, n/ep=0, n/st=10, rew=5.74]                                                                                                                                                 
Epoch #72: test_reward: 10.508900 ± 2.954174, best_reward: 15.284100 ± 2.945819 in #53
Epoch #73: 100001it [05:11, 321.28it/s, env_step=7300000, len=192, loss=2.462, n/ep=0, n/st=10, rew=7.67]                                                                                                                                                 
Epoch #73: test_reward: 10.184700 ± 1.638437, best_reward: 15.284100 ± 2.945819 in #53
Epoch #74: 100001it [05:10, 322.02it/s, env_step=7400000, len=105, loss=2.435, n/ep=0, n/st=10, rew=5.79]                                                                                                                                                 
Epoch #74: test_reward: 11.664100 ± 2.619934, best_reward: 15.284100 ± 2.945819 in #53
Epoch #75: 100001it [05:10, 321.78it/s, env_step=7500000, len=115, loss=2.419, n/ep=0, n/st=10, rew=3.77]                                                                                                                                                 
Epoch #75: test_reward: 10.871200 ± 1.549796, best_reward: 15.284100 ± 2.945819 in #53
Epoch #76: 100001it [05:11, 321.34it/s, env_step=7600000, len=212, loss=2.430, n/ep=0, n/st=10, rew=9.68]                                                                                                                                                 
Epoch #76: test_reward: 8.696400 ± 3.139734, best_reward: 15.284100 ± 2.945819 in #53
Epoch #77: 100001it [05:12, 320.13it/s, env_step=7700000, len=132, loss=2.452, n/ep=0, n/st=10, rew=5.76]                                                                                                                                                 
Epoch #77: test_reward: 10.569800 ± 2.614223, best_reward: 15.284100 ± 2.945819 in #53
Epoch #78: 100001it [05:10, 322.34it/s, env_step=7800000, len=129, loss=2.433, n/ep=0, n/st=10, rew=5.67]                                                                                                                                                 
Epoch #78: test_reward: 9.605000 ± 1.692548, best_reward: 15.284100 ± 2.945819 in #53
Epoch #79: 100001it [05:11, 320.75it/s, env_step=7900000, len=117, loss=2.416, n/ep=0, n/st=10, rew=4.74]                                                                                                                                                 
Epoch #79: test_reward: 8.375300 ± 2.199524, best_reward: 15.284100 ± 2.945819 in #53
Epoch #80: 100001it [05:11, 320.67it/s, env_step=8000000, len=201, loss=2.413, n/ep=1, n/st=10, rew=10.67]                                                                                                                                                
Epoch #80: test_reward: 6.893900 ± 2.022083, best_reward: 15.284100 ± 2.945819 in #53
{'best_result': '15.28 ± 2.95',
 'best_reward': 15.284100000000002,
 'duration': '26696.47s',
 'test_episode': 8100,
 'test_speed': '776.11 step/s',
 'test_step': 1368473,
 'test_time': '1763.25s',
 'train_episode': 54710,
 'train_speed': '320.86 step/s',
 'train_step': 8000000,
 'train_time/collector': '11829.07s',
 'train_time/model': '13104.15s'}


## DEFEND THE CENTER RAINBOW REWARD SHAPING

Run: 99_20251210_234053

uv run levd.py --algorithm rainbow --scenario defend_the_center --train_levels 0 --train_maps 1 --test_levels 0 --test_maps 1 --seed 99 --epoch 80 --step-per-collect 10 --device cuda --batch-size 64

Epoch #1: 100001it [05:30, 302.41it/s, env_step=100000, len=82, loss=3.015, n/ep=0, n/st=10, rew=0.73]                                                                                                                                                                  
Epoch #1: test_reward: 4.012330 ± 1.238461, best_reward: 4.012330 ± 1.238461 in #1
Epoch #2: 100001it [05:29, 303.93it/s, env_step=200000, len=114, loss=2.829, n/ep=1, n/st=10, rew=3.62]                                                                                                                                                                 
Epoch #2: test_reward: 4.092740 ± 0.842163, best_reward: 4.092740 ± 0.842163 in #2
Epoch #3: 100001it [05:27, 305.26it/s, env_step=300000, len=62, loss=2.756, n/ep=0, n/st=10, rew=1.77]                                                                                                                                                                  
Epoch #3: test_reward: 4.414070 ± 0.857744, best_reward: 4.414070 ± 0.857744 in #3
Epoch #4: 100001it [05:28, 304.54it/s, env_step=400000, len=54, loss=2.586, n/ep=0, n/st=10, rew=-0.18]                                                                                                                                                                 
Epoch #4: test_reward: 4.290240 ± 1.058840, best_reward: 4.414070 ± 0.857744 in #3
Epoch #5: 100001it [05:32, 300.48it/s, env_step=500000, len=76, loss=2.532, n/ep=0, n/st=10, rew=1.71]                                                                                                                                                                  
Epoch #5: test_reward: 4.342640 ± 1.313181, best_reward: 4.414070 ± 0.857744 in #3
Epoch #6: 100001it [05:38, 295.60it/s, env_step=600000, len=102, loss=2.445, n/ep=0, n/st=10, rew=3.64]                                                                                                                                                                 
Epoch #6: test_reward: 5.960640 ± 1.106004, best_reward: 5.960640 ± 1.106004 in #6
Epoch #7: 100001it [05:37, 296.15it/s, env_step=700000, len=137, loss=2.482, n/ep=0, n/st=10, rew=4.67]                                                                                                                                                                 
Epoch #7: test_reward: 6.732730 ± 0.936177, best_reward: 6.732730 ± 0.936177 in #7
Epoch #8: 100001it [05:37, 295.94it/s, env_step=800000, len=168, loss=2.471, n/ep=0, n/st=10, rew=6.62]                                                                                                                                                                 
Epoch #8: test_reward: 6.788760 ± 1.007655, best_reward: 6.788760 ± 1.007655 in #8
Epoch #9: 100001it [05:36, 297.03it/s, env_step=900000, len=142, loss=2.423, n/ep=0, n/st=10, rew=7.66]                                                                                                                                                                 
Epoch #9: test_reward: 7.427400 ± 2.362749, best_reward: 7.427400 ± 2.362749 in #9
Epoch #10: 100001it [05:36, 297.03it/s, env_step=1000000, len=192, loss=2.334, n/ep=0, n/st=10, rew=8.62]                                                                                                                                                               
Epoch #10: test_reward: 9.750150 ± 2.413976, best_reward: 9.750150 ± 2.413976 in #10
Epoch #11: 100001it [05:36, 297.33it/s, env_step=1100000, len=105, loss=2.313, n/ep=0, n/st=10, rew=3.68]                                                                                                                                                               
Epoch #11: test_reward: 7.513030 ± 1.095738, best_reward: 9.750150 ± 2.413976 in #10
Epoch #12: 100001it [05:37, 296.11it/s, env_step=1200000, len=106, loss=2.318, n/ep=0, n/st=10, rew=2.72]                                                                                                                                                               
Epoch #12: test_reward: 6.352870 ± 1.321393, best_reward: 9.750150 ± 2.413976 in #10
Epoch #13: 100001it [05:38, 295.82it/s, env_step=1300000, len=121, loss=2.343, n/ep=0, n/st=10, rew=4.65]                                                                                                                                                               
Epoch #13: test_reward: 5.158650 ± 1.398804, best_reward: 9.750150 ± 2.413976 in #10
Epoch #14: 100001it [05:38, 295.65it/s, env_step=1400000, len=112, loss=2.321, n/ep=0, n/st=10, rew=4.64]                                                                                                                                                               
Epoch #14: test_reward: 5.643290 ± 1.150263, best_reward: 9.750150 ± 2.413976 in #10
Epoch #15: 100001it [05:37, 296.10it/s, env_step=1500000, len=154, loss=2.260, n/ep=0, n/st=10, rew=6.70]                                                                                                                                                               
Epoch #15: test_reward: 6.249550 ± 1.438609, best_reward: 9.750150 ± 2.413976 in #10
Epoch #16: 100001it [05:37, 296.63it/s, env_step=1600000, len=158, loss=2.233, n/ep=0, n/st=10, rew=6.61]                                                                                                                                                               
Epoch #16: test_reward: 5.881080 ± 1.279683, best_reward: 9.750150 ± 2.413976 in #10
Epoch #17: 100001it [05:36, 296.81it/s, env_step=1700000, len=149, loss=2.218, n/ep=1, n/st=10, rew=5.64]                                                                                                                                                               
Epoch #17: test_reward: 5.854710 ± 1.129838, best_reward: 9.750150 ± 2.413976 in #10
Epoch #18: 100001it [05:37, 296.64it/s, env_step=1800000, len=119, loss=2.134, n/ep=0, n/st=10, rew=2.62]                                                                                                                                                               
Epoch #18: test_reward: 6.082620 ± 0.996081, best_reward: 9.750150 ± 2.413976 in #10
Epoch #19: 100001it [05:37, 295.94it/s, env_step=1900000, len=177, loss=2.058, n/ep=0, n/st=10, rew=7.67]                                                                                                                                                               
Epoch #19: test_reward: 6.536950 ± 1.565707, best_reward: 9.750150 ± 2.413976 in #10
Epoch #20: 100001it [05:36, 296.84it/s, env_step=2000000, len=185, loss=2.115, n/ep=0, n/st=10, rew=7.65]                                                                                                                                                               
Epoch #20: test_reward: 8.060130 ± 2.715872, best_reward: 9.750150 ± 2.413976 in #10
Epoch #21: 100001it [05:36, 296.78it/s, env_step=2100000, len=127, loss=1.978, n/ep=0, n/st=10, rew=6.66]                                                                                                                                                               
Epoch #21: test_reward: 9.323720 ± 2.299560, best_reward: 9.750150 ± 2.413976 in #10
Epoch #22: 100001it [05:35, 297.65it/s, env_step=2200000, len=156, loss=2.025, n/ep=0, n/st=10, rew=8.62]                                                                                                                                                               
Epoch #22: test_reward: 9.375610 ± 2.371425, best_reward: 9.750150 ± 2.413976 in #10
Epoch #23: 100001it [05:37, 296.45it/s, env_step=2300000, len=183, loss=1.959, n/ep=0, n/st=10, rew=7.63]                                                                                                                                                               
Epoch #23: test_reward: 7.995000 ± 1.924834, best_reward: 9.750150 ± 2.413976 in #10
Epoch #24: 100001it [05:37, 296.73it/s, env_step=2400000, len=154, loss=1.933, n/ep=1, n/st=10, rew=5.65]                                                                                                                                                               
Epoch #24: test_reward: 7.058020 ± 1.632412, best_reward: 9.750150 ± 2.413976 in #10
Epoch #25: 100001it [05:38, 295.25it/s, env_step=2500000, len=188, loss=1.947, n/ep=0, n/st=10, rew=7.58]                                                                                                                                                               
Epoch #25: test_reward: 6.516000 ± 1.499861, best_reward: 9.750150 ± 2.413976 in #10
Epoch #26: 100001it [05:37, 296.29it/s, env_step=2600000, len=150, loss=1.944, n/ep=0, n/st=10, rew=6.63]                                                                                                                                                               
Epoch #26: test_reward: 5.691320 ± 1.404634, best_reward: 9.750150 ± 2.413976 in #10
Epoch #27: 100001it [05:38, 295.79it/s, env_step=2700000, len=117, loss=1.936, n/ep=1, n/st=10, rew=6.72]                                                                                                                                                               
Epoch #27: test_reward: 8.244120 ± 2.196207, best_reward: 9.750150 ± 2.413976 in #10
Epoch #28: 100001it [05:35, 297.66it/s, env_step=2800000, len=192, loss=1.893, n/ep=0, n/st=10, rew=7.67]                                                                                                                                                               
Epoch #28: test_reward: 9.270690 ± 2.125327, best_reward: 9.750150 ± 2.413976 in #10
Epoch #29: 100001it [05:36, 297.41it/s, env_step=2900000, len=108, loss=1.842, n/ep=0, n/st=10, rew=4.64]                                                                                                                                                               
Epoch #29: test_reward: 8.681920 ± 2.310660, best_reward: 9.750150 ± 2.413976 in #10
Epoch #30: 100001it [05:37, 296.43it/s, env_step=3000000, len=180, loss=1.863, n/ep=0, n/st=10, rew=6.59]                                                                                                                                                               
Epoch #30: test_reward: 6.230650 ± 1.001341, best_reward: 9.750150 ± 2.413976 in #10
Epoch #31: 100001it [05:36, 297.24it/s, env_step=3100000, len=117, loss=1.770, n/ep=0, n/st=10, rew=4.59]                                                                                                                                                               
Epoch #31: test_reward: 6.822750 ± 1.267270, best_reward: 9.750150 ± 2.413976 in #10
Epoch #32: 100001it [05:37, 296.58it/s, env_step=3200000, len=129, loss=1.787, n/ep=0, n/st=10, rew=5.66]                                                                                                                                                               
Epoch #32: test_reward: 7.403420 ± 1.236965, best_reward: 9.750150 ± 2.413976 in #10
Epoch #33: 100001it [05:37, 296.71it/s, env_step=3300000, len=182, loss=1.783, n/ep=0, n/st=10, rew=7.69]                                                                                                                                                               
Epoch #33: test_reward: 8.866650 ± 2.410031, best_reward: 9.750150 ± 2.413976 in #10
Epoch #34: 100001it [05:36, 297.36it/s, env_step=3400000, len=129, loss=1.832, n/ep=0, n/st=10, rew=5.59]                                                                                                                                                               
Epoch #34: test_reward: 7.165360 ± 1.109555, best_reward: 9.750150 ± 2.413976 in #10
Epoch #35: 100001it [05:36, 297.01it/s, env_step=3500000, len=135, loss=1.760, n/ep=0, n/st=10, rew=5.62]                                                                                                                                                               
Epoch #35: test_reward: 7.149030 ± 1.362100, best_reward: 9.750150 ± 2.413976 in #10
Epoch #36: 100001it [05:37, 296.21it/s, env_step=3600000, len=194, loss=1.739, n/ep=0, n/st=10, rew=7.63]                                                                                                                                                               
Epoch #36: test_reward: 6.325100 ± 1.171648, best_reward: 9.750150 ± 2.413976 in #10
Epoch #37: 100001it [05:37, 296.21it/s, env_step=3700000, len=133, loss=1.658, n/ep=0, n/st=10, rew=8.58]                                                                                                                                                               
Epoch #37: test_reward: 7.036630 ± 1.131672, best_reward: 9.750150 ± 2.413976 in #10
Epoch #38: 100001it [05:36, 297.44it/s, env_step=3800000, len=117, loss=1.647, n/ep=0, n/st=10, rew=5.66]                                                                                                                                                               
Epoch #38: test_reward: 7.264140 ± 1.154289, best_reward: 9.750150 ± 2.413976 in #10
Epoch #39: 100001it [05:37, 295.97it/s, env_step=3900000, len=227, loss=1.648, n/ep=0, n/st=10, rew=7.62]                                                                                                                                                               
Epoch #39: test_reward: 7.124840 ± 1.161003, best_reward: 9.750150 ± 2.413976 in #10
Epoch #40: 100001it [05:37, 296.56it/s, env_step=4000000, len=186, loss=1.641, n/ep=0, n/st=10, rew=7.63]                                                                                                                                                               
Epoch #40: test_reward: 6.150530 ± 1.127976, best_reward: 9.750150 ± 2.413976 in #10
Epoch #41: 100001it [05:36, 296.92it/s, env_step=4100000, len=189, loss=1.571, n/ep=0, n/st=10, rew=8.54]                                                                                                                                                               
Epoch #41: test_reward: 6.763380 ± 1.152766, best_reward: 9.750150 ± 2.413976 in #10
Epoch #42: 100001it [05:37, 295.93it/s, env_step=4200000, len=150, loss=1.601, n/ep=0, n/st=10, rew=5.60]                                                                                                                                                               
Epoch #42: test_reward: 6.096360 ± 1.124373, best_reward: 9.750150 ± 2.413976 in #10
Epoch #43: 100001it [05:37, 296.43it/s, env_step=4300000, len=151, loss=1.606, n/ep=0, n/st=10, rew=8.70]                                                                                                                                                               
Epoch #43: test_reward: 7.235340 ± 1.399989, best_reward: 9.750150 ± 2.413976 in #10
Epoch #44: 100001it [05:37, 296.42it/s, env_step=4400000, len=159, loss=1.613, n/ep=0, n/st=10, rew=7.59]                                                                                                                                                               
Epoch #44: test_reward: 6.754850 ± 1.125944, best_reward: 9.750150 ± 2.413976 in #10
Epoch #45: 100001it [05:38, 295.09it/s, env_step=4500000, len=158, loss=1.616, n/ep=0, n/st=10, rew=6.64]                                                                                                                                                               
Epoch #45: test_reward: 6.855380 ± 1.372705, best_reward: 9.750150 ± 2.413976 in #10
Epoch #46: 100001it [05:36, 296.89it/s, env_step=4600000, len=155, loss=1.504, n/ep=0, n/st=10, rew=5.61]                                                                                                                                                               
Epoch #46: test_reward: 6.362940 ± 1.181616, best_reward: 9.750150 ± 2.413976 in #10
Epoch #47: 100001it [05:38, 295.85it/s, env_step=4700000, len=152, loss=1.567, n/ep=0, n/st=10, rew=5.63]                                                                                                                                                               
Epoch #47: test_reward: 6.422140 ± 1.337924, best_reward: 9.750150 ± 2.413976 in #10
Epoch #48: 100001it [05:37, 296.53it/s, env_step=4800000, len=103, loss=1.541, n/ep=0, n/st=10, rew=2.75]                                                                                                                                                               
Epoch #48: test_reward: 6.255920 ± 1.377319, best_reward: 9.750150 ± 2.413976 in #10
Epoch #49: 100001it [05:37, 296.02it/s, env_step=4900000, len=170, loss=1.563, n/ep=0, n/st=10, rew=7.71]                                                                                                                                                               
Epoch #49: test_reward: 5.668410 ± 1.226154, best_reward: 9.750150 ± 2.413976 in #10
Epoch #50: 100001it [05:37, 296.04it/s, env_step=5000000, len=108, loss=1.506, n/ep=0, n/st=10, rew=3.69]                                                                                                                                                               
Epoch #50: test_reward: 7.078750 ± 1.466725, best_reward: 9.750150 ± 2.413976 in #10
Epoch #51: 100001it [05:36, 296.77it/s, env_step=5100000, len=105, loss=1.547, n/ep=0, n/st=10, rew=3.63]                                                                                                                                                               
Epoch #51: test_reward: 7.000630 ± 1.188292, best_reward: 9.750150 ± 2.413976 in #10
Epoch #52: 100001it [05:37, 296.06it/s, env_step=5200000, len=118, loss=1.572, n/ep=0, n/st=10, rew=3.68]                                                                                                                                                               
Epoch #52: test_reward: 6.596450 ± 1.126877, best_reward: 9.750150 ± 2.413976 in #10
Epoch #53: 100001it [05:37, 296.51it/s, env_step=5300000, len=156, loss=1.548, n/ep=0, n/st=10, rew=7.70]                                                                                                                                                               
Epoch #53: test_reward: 4.761580 ± 1.582664, best_reward: 9.750150 ± 2.413976 in #10
Epoch #54: 100001it [05:36, 297.33it/s, env_step=5400000, len=180, loss=1.558, n/ep=0, n/st=10, rew=6.66]                                                                                                                                                               
Epoch #54: test_reward: 5.919810 ± 1.255625, best_reward: 9.750150 ± 2.413976 in #10
Epoch #55: 100001it [05:37, 296.60it/s, env_step=5500000, len=144, loss=1.566, n/ep=0, n/st=10, rew=5.67]                                                                                                                                                               
Epoch #55: test_reward: 6.761300 ± 1.000884, best_reward: 9.750150 ± 2.413976 in #10
Epoch #56: 100001it [05:36, 297.30it/s, env_step=5600000, len=203, loss=1.573, n/ep=0, n/st=10, rew=8.65]                                                                                                                                                               
Epoch #56: test_reward: 7.675890 ± 0.835569, best_reward: 9.750150 ± 2.413976 in #10
Epoch #57: 100001it [05:37, 296.07it/s, env_step=5700000, len=108, loss=1.524, n/ep=0, n/st=10, rew=4.75]                                                                                                                                                               
Epoch #57: test_reward: 7.426110 ± 1.312175, best_reward: 9.750150 ± 2.413976 in #10
Epoch #58: 100001it [05:36, 296.77it/s, env_step=5800000, len=77, loss=1.558, n/ep=0, n/st=10, rew=2.80]                                                                                                                                                                
Epoch #58: test_reward: 6.070420 ± 1.523487, best_reward: 9.750150 ± 2.413976 in #10
Epoch #59: 100001it [05:36, 297.34it/s, env_step=5900000, len=141, loss=1.587, n/ep=0, n/st=10, rew=6.61]                                                                                                                                                               
Epoch #59: test_reward: 6.548520 ± 1.685785, best_reward: 9.750150 ± 2.413976 in #10
Epoch #60: 100001it [05:36, 297.18it/s, env_step=6000000, len=187, loss=1.527, n/ep=0, n/st=10, rew=5.63]                                                                                                                                                               
Epoch #60: test_reward: 7.746810 ± 1.221851, best_reward: 9.750150 ± 2.413976 in #10
Epoch #61: 100001it [05:36, 297.26it/s, env_step=6100000, len=122, loss=1.589, n/ep=0, n/st=10, rew=6.69]                                                                                                                                                               
Epoch #61: test_reward: 7.054600 ± 1.241993, best_reward: 9.750150 ± 2.413976 in #10
Epoch #62: 100001it [05:36, 296.97it/s, env_step=6200000, len=114, loss=1.559, n/ep=0, n/st=10, rew=4.75]                                                                                                                                                               
Epoch #62: test_reward: 6.714320 ± 1.038166, best_reward: 9.750150 ± 2.413976 in #10
Epoch #63: 100001it [05:35, 297.69it/s, env_step=6300000, len=168, loss=1.540, n/ep=0, n/st=10, rew=7.62]                                                                                                                                                               
Epoch #63: test_reward: 6.706580 ± 1.319918, best_reward: 9.750150 ± 2.413976 in #10
Epoch #64: 100001it [05:36, 296.92it/s, env_step=6400000, len=137, loss=1.531, n/ep=0, n/st=10, rew=6.61]                                                                                                                                                               
Epoch #64: test_reward: 6.937890 ± 1.152271, best_reward: 9.750150 ± 2.413976 in #10
Epoch #65: 100001it [05:37, 296.11it/s, env_step=6500000, len=162, loss=1.564, n/ep=0, n/st=10, rew=5.68]                                                                                                                                                               
Epoch #65: test_reward: 7.565730 ± 1.272745, best_reward: 9.750150 ± 2.413976 in #10
Epoch #66: 100001it [05:37, 296.61it/s, env_step=6600000, len=185, loss=1.537, n/ep=0, n/st=10, rew=7.63]                                                                                                                                                               
Epoch #66: test_reward: 7.418480 ± 1.284846, best_reward: 9.750150 ± 2.413976 in #10
Epoch #67: 100001it [05:36, 297.00it/s, env_step=6700000, len=93, loss=1.555, n/ep=0, n/st=10, rew=4.73]                                                                                                                                                                
Epoch #67: test_reward: 6.195640 ± 1.245520, best_reward: 9.750150 ± 2.413976 in #10
Epoch #68: 100001it [05:43, 291.27it/s, env_step=6800000, len=170, loss=1.550, n/ep=0, n/st=10, rew=7.60]                                                                                                                                                               
Epoch #68: test_reward: 6.320660 ± 1.887721, best_reward: 9.750150 ± 2.413976 in #10
Epoch #69: 100001it [05:40, 294.09it/s, env_step=6900000, len=158, loss=1.549, n/ep=0, n/st=10, rew=4.58]                                                                                                                                                               
Epoch #69: test_reward: 6.620380 ± 1.651864, best_reward: 9.750150 ± 2.413976 in #10
Epoch #70: 100001it [05:38, 295.48it/s, env_step=7000000, len=141, loss=1.545, n/ep=0, n/st=10, rew=5.66]                                                                                                                                                               
Epoch #70: test_reward: 6.757540 ± 1.613582, best_reward: 9.750150 ± 2.413976 in #10
Epoch #71: 100001it [05:39, 294.76it/s, env_step=7100000, len=83, loss=1.517, n/ep=0, n/st=10, rew=3.77]                                                                                                                                                                
Epoch #71: test_reward: 7.526540 ± 2.180611, best_reward: 9.750150 ± 2.413976 in #10
Epoch #72: 100001it [05:38, 295.03it/s, env_step=7200000, len=109, loss=1.567, n/ep=0, n/st=10, rew=3.67]                                                                                                                                                               
Epoch #72: test_reward: 8.686250 ± 1.912245, best_reward: 9.750150 ± 2.413976 in #10
Epoch #73: 100001it [05:38, 295.23it/s, env_step=7300000, len=125, loss=1.526, n/ep=0, n/st=10, rew=6.69]                                                                                                                                                               
Epoch #73: test_reward: 9.156410 ± 1.701080, best_reward: 9.750150 ± 2.413976 in #10
Epoch #74: 100001it [05:38, 295.09it/s, env_step=7400000, len=161, loss=1.519, n/ep=0, n/st=10, rew=7.62]                                                                                                                                                               
Epoch #74: test_reward: 6.833970 ± 2.178868, best_reward: 9.750150 ± 2.413976 in #10
Epoch #75: 100001it [05:39, 294.64it/s, env_step=7500000, len=129, loss=1.591, n/ep=0, n/st=10, rew=6.64]                                                                                                                                                               
Epoch #75: test_reward: 6.762010 ± 2.281580, best_reward: 9.750150 ± 2.413976 in #10
Epoch #76: 100001it [05:39, 294.83it/s, env_step=7600000, len=94, loss=1.557, n/ep=1, n/st=10, rew=2.76]                                                                                                                                                                
Epoch #76: test_reward: 7.051450 ± 1.846579, best_reward: 9.750150 ± 2.413976 in #10
Epoch #77: 100001it [05:39, 294.87it/s, env_step=7700000, len=108, loss=1.564, n/ep=0, n/st=10, rew=4.72]                                                                                                                                                               
Epoch #77: test_reward: 7.077820 ± 2.585642, best_reward: 9.750150 ± 2.413976 in #10
Epoch #78: 100001it [05:40, 294.11it/s, env_step=7800000, len=218, loss=1.540, n/ep=0, n/st=10, rew=7.67]                                                                                                                                                               
Epoch #78: test_reward: 6.861730 ± 2.246348, best_reward: 9.750150 ± 2.413976 in #10
Epoch #79: 100001it [05:39, 294.87it/s, env_step=7900000, len=190, loss=1.574, n/ep=0, n/st=10, rew=8.66]                                                                                                                                                               
Epoch #79: test_reward: 6.160290 ± 2.072276, best_reward: 9.750150 ± 2.413976 in #10
Epoch #80: 100001it [05:38, 295.09it/s, env_step=8000000, len=111, loss=1.578, n/ep=0, n/st=10, rew=3.63]                                                                                                                                                               
Epoch #80: test_reward: 5.485550 ± 1.900163, best_reward: 9.750150 ± 2.413976 in #10
{'best_result': '9.75 ± 2.41',
 'best_reward': 9.750150000000005,
 'duration': '28632.19s',
 'test_episode': 8100,
 'test_speed': '744.70 step/s',
 'test_step': 1239311,
 'test_time': '1664.16s',
 'train_episode': 56829,
 'train_speed': '296.65 step/s',
 'train_step': 8000000,
 'train_time/collector': '13068.07s',
 'train_time/model': '13899.95s'}


## DEFEND THE CENTER DTQN

Run: 99_20251213_141542

uv run levd.py --algorithm dtqn --scenario defend_the_center --train_levels 0 --train_maps 1 --test_levels 0 --t
est_maps 1 --seed 99 --epoch 80 --step-per-collect 10 --device cuda --batch-size 64 --frame-stack 4

Epoch #1: 100001it [06:51, 242.82it/s, env_step=100000, len=112, loss=0.100, n/ep=0, n/st=10, rew=1.69]                                                                           
Epoch #1: test_reward: 5.160900 ± 0.931921, best_reward: 5.160900 ± 0.931921 in #1
Epoch #2: 100001it [06:51, 242.79it/s, env_step=200000, len=79, loss=0.112, n/ep=0, n/st=10, rew=1.76]                                                                            
Epoch #2: test_reward: 5.680300 ± 1.230316, best_reward: 5.680300 ± 1.230316 in #2
Epoch #3: 100001it [06:52, 242.56it/s, env_step=300000, len=112, loss=0.133, n/ep=0, n/st=10, rew=2.67]                                                                           
Epoch #3: test_reward: 5.312000 ± 1.349745, best_reward: 5.680300 ± 1.230316 in #2
Epoch #4: 100001it [06:52, 242.39it/s, env_step=400000, len=125, loss=0.123, n/ep=0, n/st=10, rew=6.64]                                                                           
Epoch #4: test_reward: 4.053800 ± 1.088410, best_reward: 5.680300 ± 1.230316 in #2
Epoch #5: 100001it [06:51, 243.15it/s, env_step=500000, len=116, loss=0.121, n/ep=0, n/st=10, rew=3.67]                                                                           
Epoch #5: test_reward: 5.007800 ± 1.159173, best_reward: 5.680300 ± 1.230316 in #2
Epoch #6: 100001it [06:50, 243.34it/s, env_step=600000, len=165, loss=0.133, n/ep=0, n/st=10, rew=6.67]                                                                           
Epoch #6: test_reward: 4.825900 ± 1.076148, best_reward: 5.680300 ± 1.230316 in #2
Epoch #7: 100001it [06:51, 243.22it/s, env_step=700000, len=120, loss=0.121, n/ep=0, n/st=10, rew=3.70]                                                                           
Epoch #7: test_reward: 6.538200 ± 2.215900, best_reward: 6.538200 ± 2.215900 in #7
Epoch #8: 100001it [06:50, 243.38it/s, env_step=800000, len=132, loss=0.121, n/ep=0, n/st=10, rew=5.65]                                                                           
Epoch #8: test_reward: 6.559100 ± 1.315329, best_reward: 6.559100 ± 1.315329 in #8
Epoch #9: 100001it [06:51, 243.05it/s, env_step=900000, len=159, loss=0.124, n/ep=0, n/st=10, rew=7.70]                                                                           
Epoch #9: test_reward: 7.620000 ± 1.299149, best_reward: 7.620000 ± 1.299149 in #9
Epoch #10: 100001it [06:50, 243.85it/s, env_step=1000000, len=130, loss=0.129, n/ep=0, n/st=10, rew=6.65]                                                                         
Epoch #10: test_reward: 6.472600 ± 1.131521, best_reward: 7.620000 ± 1.299149 in #9
Epoch #11: 100001it [06:50, 243.79it/s, env_step=1100000, len=165, loss=0.130, n/ep=0, n/st=10, rew=7.68]                                                                         
Epoch #11: test_reward: 8.209000 ± 1.716162, best_reward: 8.209000 ± 1.716162 in #11
Epoch #12: 100001it [06:50, 243.54it/s, env_step=1200000, len=179, loss=0.128, n/ep=0, n/st=10, rew=8.70]                                                                         
Epoch #12: test_reward: 5.764400 ± 1.359254, best_reward: 8.209000 ± 1.716162 in #11
Epoch #13: 100001it [06:50, 243.62it/s, env_step=1300000, len=134, loss=0.113, n/ep=1, n/st=10, rew=5.65]                                                                         
Epoch #13: test_reward: 5.840400 ± 1.126676, best_reward: 8.209000 ± 1.716162 in #11
Epoch #14: 100001it [06:50, 243.73it/s, env_step=1400000, len=178, loss=0.122, n/ep=0, n/st=10, rew=8.67]                                                                         
Epoch #14: test_reward: 8.417600 ± 1.335304, best_reward: 8.417600 ± 1.335304 in #14
Epoch #15: 100001it [06:49, 243.93it/s, env_step=1500000, len=181, loss=0.114, n/ep=0, n/st=10, rew=8.67]                                                                         
Epoch #15: test_reward: 8.336400 ± 1.606375, best_reward: 8.417600 ± 1.335304 in #14
Epoch #16: 100001it [06:50, 243.85it/s, env_step=1600000, len=197, loss=0.115, n/ep=0, n/st=10, rew=11.71]                                                                        
Epoch #16: test_reward: 12.555300 ± 1.609150, best_reward: 12.555300 ± 1.609150 in #16
Epoch #17: 100001it [06:49, 244.24it/s, env_step=1700000, len=183, loss=0.120, n/ep=0, n/st=10, rew=8.71]                                                                         
Epoch #17: test_reward: 9.902300 ± 2.390811, best_reward: 12.555300 ± 1.609150 in #16
Epoch #18: 100001it [06:49, 244.45it/s, env_step=1800000, len=188, loss=0.113, n/ep=1, n/st=10, rew=11.68]                                                                        
Epoch #18: test_reward: 14.952600 ± 1.370467, best_reward: 14.952600 ± 1.370467 in #18
Epoch #19: 100001it [06:49, 244.32it/s, env_step=1900000, len=215, loss=0.125, n/ep=0, n/st=10, rew=13.67]                                                                        
Epoch #19: test_reward: 9.246600 ± 3.060597, best_reward: 14.952600 ± 1.370467 in #18
Epoch #20: 100001it [06:48, 244.51it/s, env_step=2000000, len=202, loss=0.112, n/ep=0, n/st=10, rew=9.71]                                                                         
Epoch #20: test_reward: 12.741900 ± 1.962440, best_reward: 14.952600 ± 1.370467 in #18
Epoch #21: 100001it [06:49, 244.14it/s, env_step=2100000, len=239, loss=0.116, n/ep=0, n/st=10, rew=14.70]                                                                        
Epoch #21: test_reward: 10.476200 ± 3.148602, best_reward: 14.952600 ± 1.370467 in #18
Epoch #22: 100001it [06:50, 243.87it/s, env_step=2200000, len=181, loss=0.109, n/ep=0, n/st=10, rew=10.69]                                                                        
Epoch #22: test_reward: 10.843100 ± 1.628573, best_reward: 14.952600 ± 1.370467 in #18
Epoch #23: 100001it [06:50, 243.62it/s, env_step=2300000, len=205, loss=0.109, n/ep=0, n/st=10, rew=11.69]                                                                        
Epoch #23: test_reward: 15.398600 ± 1.982290, best_reward: 15.398600 ± 1.982290 in #23
Epoch #24: 100001it [06:49, 244.29it/s, env_step=2400000, len=187, loss=0.114, n/ep=0, n/st=10, rew=12.67]                                                                        
Epoch #24: test_reward: 16.631800 ± 1.941779, best_reward: 16.631800 ± 1.941779 in #24
Epoch #25: 100001it [06:49, 243.98it/s, env_step=2500000, len=197, loss=0.110, n/ep=0, n/st=10, rew=13.69]                                                                        
Epoch #25: test_reward: 13.612000 ± 2.172360, best_reward: 16.631800 ± 1.941779 in #24
Epoch #26: 100001it [06:50, 243.69it/s, env_step=2600000, len=188, loss=0.113, n/ep=0, n/st=10, rew=11.71]                                                                        
Epoch #26: test_reward: 10.459800 ± 1.659042, best_reward: 16.631800 ± 1.941779 in #24
Epoch #27: 100001it [06:50, 243.89it/s, env_step=2700000, len=184, loss=0.106, n/ep=0, n/st=10, rew=9.70]                                                                         
Epoch #27: test_reward: 12.253300 ± 1.678604, best_reward: 16.631800 ± 1.941779 in #24
Epoch #28: 100001it [06:50, 243.51it/s, env_step=2800000, len=198, loss=0.105, n/ep=0, n/st=10, rew=9.66]                                                                         
Epoch #28: test_reward: 16.261000 ± 2.001303, best_reward: 16.631800 ± 1.941779 in #24
Epoch #29: 100001it [06:49, 244.12it/s, env_step=2900000, len=176, loss=0.101, n/ep=1, n/st=10, rew=10.67]                                                                        
Epoch #29: test_reward: 14.464700 ± 2.073305, best_reward: 16.631800 ± 1.941779 in #24
Epoch #30: 100001it [06:50, 243.53it/s, env_step=3000000, len=220, loss=0.106, n/ep=0, n/st=10, rew=12.69]                                                                        
Epoch #30: test_reward: 12.044200 ± 1.905408, best_reward: 16.631800 ± 1.941779 in #24
Epoch #31: 100001it [06:50, 243.83it/s, env_step=3100000, len=209, loss=0.102, n/ep=0, n/st=10, rew=9.70]                                                                         
Epoch #31: test_reward: 9.865500 ± 1.323806, best_reward: 16.631800 ± 1.941779 in #24
Epoch #32: 100001it [06:50, 243.70it/s, env_step=3200000, len=211, loss=0.105, n/ep=1, n/st=10, rew=9.67]                                                                         
Epoch #32: test_reward: 10.851100 ± 1.464561, best_reward: 16.631800 ± 1.941779 in #24
Epoch #33: 100001it [06:50, 243.90it/s, env_step=3300000, len=155, loss=0.105, n/ep=0, n/st=10, rew=6.71]                                                                         
Epoch #33: test_reward: 9.229700 ± 1.726463, best_reward: 16.631800 ± 1.941779 in #24
Epoch #34: 100001it [06:50, 243.85it/s, env_step=3400000, len=195, loss=0.110, n/ep=1, n/st=10, rew=9.71]                                                                         
Epoch #34: test_reward: 11.261000 ± 1.970204, best_reward: 16.631800 ± 1.941779 in #24
Epoch #35: 100001it [06:50, 243.87it/s, env_step=3500000, len=129, loss=0.107, n/ep=0, n/st=10, rew=7.73]                                                                         
Epoch #35: test_reward: 12.157800 ± 2.132170, best_reward: 16.631800 ± 1.941779 in #24
Epoch #36: 100001it [06:49, 244.09it/s, env_step=3600000, len=197, loss=0.113, n/ep=0, n/st=10, rew=8.70]                                                                         
Epoch #36: test_reward: 10.234700 ± 1.483168, best_reward: 16.631800 ± 1.941779 in #24
Epoch #37: 100001it [06:49, 244.44it/s, env_step=3700000, len=186, loss=0.102, n/ep=0, n/st=10, rew=12.70]                                                                        
Epoch #37: test_reward: 10.630800 ± 1.344259, best_reward: 16.631800 ± 1.941779 in #24
Epoch #38: 100001it [06:48, 244.67it/s, env_step=3800000, len=151, loss=0.105, n/ep=0, n/st=10, rew=6.66]                                                                         
Epoch #38: test_reward: 12.813400 ± 2.563802, best_reward: 16.631800 ± 1.941779 in #24
Epoch #39: 100001it [06:49, 244.15it/s, env_step=3900000, len=190, loss=0.103, n/ep=0, n/st=10, rew=9.69]                                                                         
Epoch #39: test_reward: 13.117100 ± 2.718484, best_reward: 16.631800 ± 1.941779 in #24
Epoch #40: 100001it [06:50, 243.51it/s, env_step=4000000, len=124, loss=0.103, n/ep=0, n/st=10, rew=6.73]                                                                         
Epoch #40: test_reward: 10.435200 ± 1.303494, best_reward: 16.631800 ± 1.941779 in #24
Epoch #41: 100001it [06:50, 243.63it/s, env_step=4100000, len=194, loss=0.101, n/ep=0, n/st=10, rew=11.70]                                                                        
Epoch #41: test_reward: 10.755600 ± 2.039592, best_reward: 16.631800 ± 1.941779 in #24
Epoch #42: 100001it [06:50, 243.90it/s, env_step=4200000, len=85, loss=0.103, n/ep=0, n/st=10, rew=2.80]                                                                          
Epoch #42: test_reward: 11.428000 ± 2.111966, best_reward: 16.631800 ± 1.941779 in #24
Epoch #43: 100001it [06:50, 243.82it/s, env_step=4300000, len=252, loss=0.112, n/ep=0, n/st=10, rew=10.62]                                                                        
Epoch #43: test_reward: 15.235800 ± 2.346122, best_reward: 16.631800 ± 1.941779 in #24
Epoch #44: 100001it [06:49, 244.18it/s, env_step=4400000, len=132, loss=0.106, n/ep=0, n/st=10, rew=7.77]                                                                         
Epoch #44: test_reward: 11.191200 ± 3.085509, best_reward: 16.631800 ± 1.941779 in #24
Epoch #45: 100001it [06:49, 244.26it/s, env_step=4500000, len=169, loss=0.112, n/ep=0, n/st=10, rew=8.67]                                                                         
Epoch #45: test_reward: 10.494200 ± 1.535865, best_reward: 16.631800 ± 1.941779 in #24
Epoch #46: 100001it [06:49, 244.39it/s, env_step=4600000, len=193, loss=0.103, n/ep=0, n/st=10, rew=7.71]                                                                         
Epoch #46: test_reward: 12.740500 ± 2.629831, best_reward: 16.631800 ± 1.941779 in #24
Epoch #47: 100001it [06:49, 244.02it/s, env_step=4700000, len=210, loss=0.110, n/ep=0, n/st=10, rew=12.68]                                                                        
Epoch #47: test_reward: 12.926200 ± 2.773893, best_reward: 16.631800 ± 1.941779 in #24
Epoch #48: 100001it [06:50, 243.72it/s, env_step=4800000, len=151, loss=0.120, n/ep=0, n/st=10, rew=9.70]                                                                         
Epoch #48: test_reward: 10.282400 ± 1.498098, best_reward: 16.631800 ± 1.941779 in #24
Epoch #49: 100001it [06:49, 243.96it/s, env_step=4900000, len=129, loss=0.113, n/ep=0, n/st=10, rew=5.69]                                                                         
Epoch #49: test_reward: 9.861200 ± 1.265821, best_reward: 16.631800 ± 1.941779 in #24
Epoch #50: 100001it [06:50, 243.72it/s, env_step=5000000, len=214, loss=0.103, n/ep=0, n/st=10, rew=11.71]                                                                        
Epoch #50: test_reward: 11.551900 ± 1.579859, best_reward: 16.631800 ± 1.941779 in #24
Epoch #51: 100001it [06:49, 243.93it/s, env_step=5100000, len=207, loss=0.102, n/ep=0, n/st=10, rew=13.68]                                                                        
Epoch #51: test_reward: 10.630800 ± 1.950249, best_reward: 16.631800 ± 1.941779 in #24
Epoch #52: 100001it [06:49, 243.93it/s, env_step=5200000, len=147, loss=0.106, n/ep=1, n/st=10, rew=8.67]                                                                         
Epoch #52: test_reward: 10.291100 ± 1.718107, best_reward: 16.631800 ± 1.941779 in #24
Epoch #53: 100001it [06:49, 244.04it/s, env_step=5300000, len=180, loss=0.100, n/ep=0, n/st=10, rew=9.69]                                                                         
Epoch #53: test_reward: 10.361400 ± 1.439237, best_reward: 16.631800 ± 1.941779 in #24
Epoch #54: 100001it [06:50, 243.33it/s, env_step=5400000, len=172, loss=0.097, n/ep=0, n/st=10, rew=10.71]                                                                        
Epoch #54: test_reward: 10.732900 ± 1.283961, best_reward: 16.631800 ± 1.941779 in #24
Epoch #55: 100001it [06:49, 243.96it/s, env_step=5500000, len=156, loss=0.104, n/ep=0, n/st=10, rew=7.71]                                                                         
Epoch #55: test_reward: 10.052100 ± 1.754528, best_reward: 16.631800 ± 1.941779 in #24
Epoch #56: 100001it [06:50, 243.40it/s, env_step=5600000, len=199, loss=0.095, n/ep=0, n/st=10, rew=10.66]                                                                        
Epoch #56: test_reward: 9.252700 ± 1.200745, best_reward: 16.631800 ± 1.941779 in #24
Epoch #57: 100001it [06:49, 244.10it/s, env_step=5700000, len=105, loss=0.097, n/ep=0, n/st=10, rew=3.74]                                                                         
Epoch #57: test_reward: 6.706800 ± 2.674245, best_reward: 16.631800 ± 1.941779 in #24
Epoch #58: 100001it [06:49, 243.97it/s, env_step=5800000, len=174, loss=0.108, n/ep=0, n/st=10, rew=9.70]                                                                         
Epoch #58: test_reward: 8.742100 ± 1.816327, best_reward: 16.631800 ± 1.941779 in #24
Epoch #59: 100001it [06:49, 244.23it/s, env_step=5900000, len=146, loss=0.108, n/ep=0, n/st=10, rew=6.67]                                                                         
Epoch #59: test_reward: 9.383500 ± 2.087689, best_reward: 16.631800 ± 1.941779 in #24
Epoch #60: 100001it [06:49, 244.04it/s, env_step=6000000, len=193, loss=0.104, n/ep=0, n/st=10, rew=10.68]                                                                        
Epoch #60: test_reward: 15.699200 ± 1.988431, best_reward: 16.631800 ± 1.941779 in #24
Epoch #61: 100001it [06:49, 244.36it/s, env_step=6100000, len=231, loss=0.101, n/ep=1, n/st=10, rew=13.67]                                                                        
Epoch #61: test_reward: 11.868200 ± 2.053126, best_reward: 16.631800 ± 1.941779 in #24
Epoch #62: 100001it [06:49, 244.48it/s, env_step=6200000, len=204, loss=0.103, n/ep=0, n/st=10, rew=11.67]                                                                        
Epoch #62: test_reward: 14.229500 ± 2.573282, best_reward: 16.631800 ± 1.941779 in #24
Epoch #63: 100001it [06:49, 244.30it/s, env_step=6300000, len=169, loss=0.115, n/ep=0, n/st=10, rew=8.67]                                                                         
Epoch #63: test_reward: 11.198300 ± 1.595932, best_reward: 16.631800 ± 1.941779 in #24
Epoch #64: 100001it [06:48, 244.68it/s, env_step=6400000, len=178, loss=0.100, n/ep=0, n/st=10, rew=8.65]                                                                         
Epoch #64: test_reward: 9.562800 ± 1.043415, best_reward: 16.631800 ± 1.941779 in #24
Epoch #65: 100001it [06:50, 243.66it/s, env_step=6500000, len=247, loss=0.103, n/ep=0, n/st=10, rew=10.66]                                                                        
Epoch #65: test_reward: 10.141600 ± 1.867082, best_reward: 16.631800 ± 1.941779 in #24
Epoch #66: 100001it [06:49, 244.18it/s, env_step=6600000, len=197, loss=0.102, n/ep=0, n/st=10, rew=9.62]                                                                         
Epoch #66: test_reward: 9.807900 ± 1.287020, best_reward: 16.631800 ± 1.941779 in #24
Epoch #67: 100001it [06:49, 244.34it/s, env_step=6700000, len=135, loss=0.100, n/ep=0, n/st=10, rew=6.63]                                                                         
Epoch #67: test_reward: 10.731500 ± 1.527664, best_reward: 16.631800 ± 1.941779 in #24
Epoch #68: 100001it [06:50, 243.59it/s, env_step=6800000, len=195, loss=0.105, n/ep=0, n/st=10, rew=8.64]                                                                         
Epoch #68: test_reward: 10.440100 ± 1.309399, best_reward: 16.631800 ± 1.941779 in #24
Epoch #69: 100001it [06:50, 243.74it/s, env_step=6900000, len=173, loss=0.093, n/ep=0, n/st=10, rew=7.69]                                                                         
Epoch #69: test_reward: 10.679700 ± 1.192530, best_reward: 16.631800 ± 1.941779 in #24
Epoch #70:  20%|###########1                                            | 19990/100000.0 [01:22<05:33, 240.03it/s, env_step=6919980, len=71, loss=nan, n/ep=0, n/st=10, rew=-0.07]NaN or Inf found in input tensor.
Epoch #70:  30%|#################                                        | 29980/100000.0 [02:03<04:52, 239.76it/s, env_step=6929980, len=64, loss=nan, n/ep=1, n/st=10, rew=0.92]NaN or Inf found in input tensor.
Epoch #70:  40%|######################7                                  | 39980/100000.0 [02:44<04:10, 239.74it/s, env_step=6939980, len=67, loss=nan, n/ep=0, n/st=10, rew=0.95]NaN or Inf found in input tensor.
Epoch #70:  50%|############################4                            | 49990/100000.0 [03:26<03:27, 241.28it/s, env_step=6949980, len=79, loss=nan, n/ep=1, n/st=10, rew=0.92]NaN or Inf found in input tensor.
Epoch #70:  60%|##################################1                      | 59980/100000.0 [04:07<02:44, 243.39it/s, env_step=6959980, len=73, loss=nan, n/ep=0, n/st=10, rew=0.94]NaN or Inf found in input tensor.
Epoch #70:  70%|#######################################8                 | 69980/100000.0 [04:49<02:02, 244.50it/s, env_step=6969980, len=86, loss=nan, n/ep=0, n/st=10, rew=0.91]NaN or Inf found in input tensor.
Epoch #70:  80%|############################################7           | 79990/100000.0 [05:30<01:23, 238.23it/s, env_step=6979980, len=77, loss=nan, n/ep=0, n/st=10, rew=-0.06]NaN or Inf found in input tensor.
Epoch #70:  90%|###################################################2     | 89980/100000.0 [06:11<00:40, 247.40it/s, env_step=6989980, len=72, loss=nan, n/ep=0, n/st=10, rew=1.91]NaN or Inf found in input tensor.
Epoch #70: 100%|#######################################################9| 99980/100000.0 [06:53<00:00, 241.85it/s, env_step=6999980, len=77, loss=nan, n/ep=0, n/st=10, rew=-0.06]NaN or Inf found in input tensor.
Epoch #70: 100001it [06:53, 241.98it/s, env_step=7000000, len=77, loss=nan, n/ep=0, n/st=10, rew=-0.06]                                                                           
Epoch #70: test_reward: -0.041200 ± 0.011856, best_reward: 16.631800 ± 1.941779 in #24
Epoch #71:  10%|#####6                                                   | 9980/100000.0 [00:41<06:04, 246.69it/s, env_step=7009980, len=78, loss=nan, n/ep=0, n/st=10, rew=-0.07]NaN or Inf found in input tensor.
Epoch #71:  20%|###########1                                            | 19990/100000.0 [01:22<05:29, 243.15it/s, env_step=7019980, len=61, loss=nan, n/ep=0, n/st=10, rew=-0.06]NaN or Inf found in input tensor.
Epoch #71:  30%|################7                                       | 29980/100000.0 [02:04<04:51, 240.20it/s, env_step=7029980, len=77, loss=nan, n/ep=1, n/st=10, rew=-0.05]NaN or Inf found in input tensor.
Epoch #71:  40%|######################3                                 | 39980/100000.0 [02:45<04:15, 234.71it/s, env_step=7039980, len=68, loss=nan, n/ep=1, n/st=10, rew=-0.05]NaN or Inf found in input tensor.
Epoch #71:  50%|############################4                            | 49990/100000.0 [03:26<03:27, 240.78it/s, env_step=7049980, len=51, loss=nan, n/ep=1, n/st=10, rew=0.96]NaN or Inf found in input tensor.
Epoch #71:  60%|#################################5                      | 59980/100000.0 [04:07<02:45, 241.26it/s, env_step=7059980, len=75, loss=nan, n/ep=0, n/st=10, rew=-0.09]NaN or Inf found in input tensor.
Epoch #71:  70%|#######################################1                | 69980/100000.0 [04:49<02:04, 241.49it/s, env_step=7069980, len=58, loss=nan, n/ep=0, n/st=10, rew=-0.05]NaN or Inf found in input tensor.
Epoch #71:  80%|############################################7           | 79990/100000.0 [05:30<01:20, 247.86it/s, env_step=7079980, len=67, loss=nan, n/ep=0, n/st=10, rew=-0.08]NaN or Inf found in input tensor.
Epoch #71:  90%|###################################################2     | 89980/100000.0 [06:11<00:41, 241.70it/s, env_step=7089980, len=82, loss=nan, n/ep=0, n/st=10, rew=0.89]NaN or Inf found in input tensor.
Epoch #71: 100%|########################################################9| 99980/100000.0 [06:52<00:00, 242.34it/s, env_step=7099980, len=64, loss=nan, n/ep=1, n/st=10, rew=0.94]NaN or Inf found in input tensor.
Epoch #71: 100001it [06:53, 242.12it/s, env_step=7100000, len=64, loss=nan, n/ep=0, n/st=10, rew=0.94]                                                                            
Epoch #71: test_reward: -0.041500 ± 0.012520, best_reward: 16.631800 ± 1.941779 in #24
Epoch #72:   4%|##5                                                       | 4320/100000.0 [00:17<06:33, 243.33it/s, env_step=7104320, len=59, loss=nan, n/ep=0, n/st=10, rew=0.94]Epoch #72:   4%|##5                                                       | 4320/100000.0 [00:17<06:34, 242.24it/s, env_step=7104320, len=59, loss=nan, n/ep=0, n/st=10, rew=0.94]
